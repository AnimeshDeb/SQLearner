[
  {
    "id": 1,
    "title": "Active Users by Country",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given a `users` table. Write a query to return, for each country, the number of users whose `status` is `'active'`.\nReturn the result sorted by `active_count` in descending order, and by `country` ascending when counts are equal.\n\n### Table: `users`\n\n| Column   | Type    | Description                        |\n|----------|---------|------------------------------------|\n| user_id  | INT     | Primary key.                       |\n| name     | VARCHAR | Name of the user.                  |\n| country  | VARCHAR | ISO country code of the user.      |\n| status   | VARCHAR | `'active'` or `'inactive'`.        |\n\n### Example\n\n**Input — users**\n\n| user_id | name   | country | status    |\n|---------|--------|---------|-----------|\n| 1       | Alice  | US      | active    |\n| 2       | Bob    | US      | inactive  |\n| 3       | Chen   | CN      | active    |\n| 4       | Diana  | CN      | active    |\n\n**Output**\n\n| country | active_count |\n|---------|--------------|\n| CN      | 2            |\n| US      | 1            |",
    "correctQuery": "SELECT country, COUNT(user_id) AS active_count FROM users WHERE status = 'active' GROUP BY country ORDER BY active_count DESC, country ASC;",
    "sourceTableQuery": "CREATE TABLE users (user_id INT PRIMARY KEY, name VARCHAR(255), country VARCHAR(3), status VARCHAR(10));\nINSERT INTO users (user_id, name, country, status) VALUES (1, 'Alice', 'US', 'active');\nINSERT INTO users (user_id, name, country, status) VALUES (2, 'Bob', 'US', 'inactive');\nINSERT INTO users (user_id, name, country, status) VALUES (3, 'Chen', 'CN', 'active');\nINSERT INTO users (user_id, name, country, status) VALUES (4, 'Diana', 'CN', 'active');",
    "hints": ["Filter the rows where status is 'active' before grouping."]
  },
  {
    "id": 2,
    "title": "Average Salary by Department",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given an `employees` table. Write a query to return the average salary for each department, rounded to 2 decimal places.\nReturn the result sorted by `department` in ascending order.\n\n### Table: `employees`\n\n| Column       | Type     | Description                      |\n|-------------|----------|---------------------------------|\n| emp_id      | INT      | Primary key.                    |\n| name        | VARCHAR  | Employee name.                  |\n| department  | VARCHAR  | Department name.                |\n| salary      | INT      | Monthly salary of the employee. |\n\n### Example\n\n**Input — employees**\n\n| emp_id | name   | department | salary |\n|--------|--------|------------|--------|\n| 1      | Alice  | IT         | 6000   |\n| 2      | Bob    | IT         | 8000   |\n| 3      | Carol  | HR         | 5000   |\n\n**Output**\n\n| department | avg_salary |\n|------------|------------|\n| HR         | 5000.00    |\n| IT         | 7000.00    |",
    "correctQuery": "SELECT department, ROUND(AVG(salary), 2) AS avg_salary FROM employees GROUP BY department ORDER BY department ASC;",
    "sourceTableQuery": "CREATE TABLE employees (emp_id INT PRIMARY KEY, name VARCHAR(255), department VARCHAR(255), salary INT);\nINSERT INTO employees (emp_id, name, department, salary) VALUES (1, 'Alice', 'IT', 6000);\nINSERT INTO employees (emp_id, name, department, salary) VALUES (2, 'Bob', 'IT', 8000);\nINSERT INTO employees (emp_id, name, department, salary) VALUES (3, 'Carol', 'HR', 5000);",
    "hints": ["Use the aggregate function AVG() and wrap it inside ROUND()."]
  },
  {
    "id": 3,
    "title": "Customers Without Orders",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given `customers` and `orders` tables. Write a query to find all customers who have **never placed an order**.\nReturn the `customer_id` and `name` of such customers, sorted by `customer_id`.\n\n### Table: `customers`\n\n| Column      | Type     | Description           |\n|------------|----------|-----------------------|\n| customer_id| INT      | Primary key.          |\n| name       | VARCHAR  | Customer name.        |\n\n### Table: `orders`\n\n| Column      | Type     | Description                      |\n|------------|----------|----------------------------------|\n| order_id   | INT      | Primary key.                     |\n| customer_id| INT      | Foreign key to `customers`.      |\n| amount     | DECIMAL  | Order amount.                    |\n\n### Example\n\n**Input — customers**\n\n| customer_id | name   |\n|-------------|--------|\n| 1           | Alice  |\n| 2           | Bob    |\n| 3           | Carol  |\n\n**Input — orders**\n\n| order_id | customer_id | amount |\n|----------|-------------|--------|\n| 10       | 1           | 50.00  |\n| 11       | 1           | 20.00  |\n\n**Output**\n\n| customer_id | name  |\n|-------------|-------|\n| 2           | Bob   |\n| 3           | Carol |",
    "correctQuery": "SELECT c.customer_id, c.name FROM customers c LEFT JOIN orders o ON c.customer_id = o.customer_id WHERE o.order_id IS NULL ORDER BY c.customer_id;",
    "sourceTableQuery": "CREATE TABLE customers (customer_id INT PRIMARY KEY, name VARCHAR(255));\nINSERT INTO customers (customer_id, name) VALUES (1, 'Alice');\nINSERT INTO customers (customer_id, name) VALUES (2, 'Bob');\nINSERT INTO customers (customer_id, name) VALUES (3, 'Carol');\nCREATE TABLE orders (order_id INT PRIMARY KEY, customer_id INT, amount DECIMAL(10,2));\nINSERT INTO orders (order_id, customer_id, amount) VALUES (10, 1, 50.00);\nINSERT INTO orders (order_id, customer_id, amount) VALUES (11, 1, 20.00);",
    "hints": ["Perform a LEFT JOIN and filter for rows where the right table's key IS NULL."]
  },
  {
    "id": 4,
    "title": "Top Selling Products",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given `products` and `order_items` tables. Each row in `order_items` represents a product sold in an order.\nWrite a query to return, for each product, the total quantity sold, sorted by `total_sold` descending.\n\n### Table: `products`\n\n| Column     | Type    | Description        |\n|-----------|---------|--------------------|\n| product_id| INT     | Primary key.       |\n| name      | VARCHAR | Product name.      |\n\n### Table: `order_items`\n\n| Column      | Type    | Description                          |\n|------------|---------|-------------------------------------|\n| order_id   | INT     | Order identifier.                   |\n| product_id | INT     | Foreign key to `products`.          |\n| quantity   | INT     | Quantity of this product in order.  |\n\n### Example\n\n**Input — products**\n\n| product_id | name      |\n|-----------|----------|\n| 1         | Keyboard |\n| 2         | Mouse    |\n\n**Input — order_items**\n\n| order_id | product_id | quantity |\n|----------|------------|----------|\n| 101      | 1          | 2        |\n| 102      | 1          | 1        |\n| 103      | 2          | 5        |\n\n**Output**\n\n| product_id | name      | total_sold |\n|-----------|----------|------------|\n| 2         | Mouse    | 5          |\n| 1         | Keyboard | 3          |",
    "correctQuery": "SELECT p.product_id, p.name, SUM(oi.quantity) AS total_sold FROM products p JOIN order_items oi ON p.product_id = oi.product_id GROUP BY p.product_id, p.name ORDER BY total_sold DESC;",
    "sourceTableQuery": "CREATE TABLE products (product_id INT PRIMARY KEY, name VARCHAR(255));\nINSERT INTO products (product_id, name) VALUES (1, 'Keyboard');\nINSERT INTO products (product_id, name) VALUES (2, 'Mouse');\nCREATE TABLE order_items (order_id INT, product_id INT, quantity INT);\nINSERT INTO order_items (order_id, product_id, quantity) VALUES (101, 1, 2);\nINSERT INTO order_items (order_id, product_id, quantity) VALUES (102, 1, 1);\nINSERT INTO order_items (order_id, product_id, quantity) VALUES (103, 2, 5);",
    "hints": ["Join the tables on product_id and use SUM() on the quantity column."]
  },
  {
    "id": 5,
    "title": "Recent Orders",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given an `orders` table. Write a query to return all orders placed in the last 7 days relative to the maximum `order_date` in the table.\nReturn all columns, sorted by `order_date` descending.\n\n### Table: `orders`\n\n| Column     | Type     | Description                  |\n|-----------|----------|-----------------------------|\n| order_id  | INT      | Primary key.                |\n| customer_id| INT     | ID of the customer.         |\n| order_date| DATE     | Date the order was placed.  |\n| amount    | DECIMAL  | Order amount.               |\n\n### Example\n\n**Input — orders**\n\n| order_id | customer_id | order_date | amount |\n|----------|-------------|------------|--------|\n| 1        | 10          | 2025-01-01 | 50.00  |\n| 2        | 11          | 2025-01-05 | 20.00  |\n| 3        | 12          | 2025-01-08 | 30.00  |\n\nAssume the maximum `order_date` is `2025-01-08`, so you should return orders from `2025-01-02` to `2025-01-08`.\n\n**Output**\n\n| order_id | customer_id | order_date | amount |\n|----------|-------------|------------|--------|\n| 3        | 12          | 2025-01-08 | 30.00  |\n| 2        | 11          | 2025-01-05 | 20.00  |",
    "correctQuery": "SELECT * FROM orders WHERE order_date >= date((SELECT MAX(order_date) FROM orders), '-7 day') ORDER BY order_date DESC;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, customer_id INT, order_date DATE, amount DECIMAL(10,2));\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (1, 10, '2025-01-01', 50.00);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (2, 11, '2025-01-05', 20.00);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (3, 12, '2025-01-08', 30.00);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (4, 13, '2025-01-10', 40.00);",
    "hints": ["Use a subquery to find the MAX(order_date), then use the date() function with '-7 day'."]
  },
  {
    "id": 6,
    "title": "Employees Earning Above Department Average",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given an `employees` table. For each department, find employees whose salary is **strictly greater** than the average salary of their department.\nReturn `emp_id`, `name`, `department`, and `salary`, sorted by `department` then `salary` descending.\n\n### Table: `employees`\n\n| Column      | Type     | Description         |\n|------------|----------|---------------------|\n| emp_id     | INT      | Primary key.        |\n| name       | VARCHAR  | Employee name.      |\n| department | VARCHAR  | Department name.    |\n| salary     | INT      | Monthly salary.     |\n\n### Example\n\n**Input — employees**\n\n| emp_id | name   | department | salary |\n|--------|--------|------------|--------|\n| 1      | Alice  | IT         | 6000   |\n| 2      | Bob    | IT         | 9000   |\n| 3      | Carol  | HR         | 5000   |\n| 4      | David  | HR         | 4000   |\n\nAverage salary IT = 7500, HR = 4500.\n\n**Output**\n\n| emp_id | name  | department | salary |\n|--------|-------|------------|--------|\n| 2      | Bob   | IT         | 9000   |\n| 3      | Carol | HR         | 5000   |",
    "correctQuery": "SELECT e.emp_id, e.name, e.department, e.salary FROM employees e JOIN (SELECT department, AVG(salary) AS avg_salary FROM employees GROUP BY department) AS d_avg ON e.department = d_avg.department WHERE e.salary > d_avg.avg_salary ORDER BY e.department, e.salary DESC;",
    "sourceTableQuery": "CREATE TABLE employees (emp_id INT PRIMARY KEY, name VARCHAR(255), department VARCHAR(255), salary INT);\nINSERT INTO employees (emp_id, name, department, salary) VALUES (1, 'Alice', 'IT', 6000);\nINSERT INTO employees (emp_id, name, department, salary) VALUES (2, 'Bob', 'IT', 9000);\nINSERT INTO employees (emp_id, name, department, salary) VALUES (3, 'Carol', 'HR', 5000);\nINSERT INTO employees (emp_id, name, department, salary) VALUES (4, 'David', 'HR', 4000);",
    "hints": ["Calculate the average salary per department in a subquery, then join it back to the main table."]
  },
  {
    "id": 7,
    "title": "Count Orders Per Day",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given an `orders` table. Write a query to count how many orders are placed on each date.\nReturn `order_date` and `order_count`, sorted by `order_date` ascending.\n\n### Table: `orders`\n\n| Column     | Type     | Description                  |\n|-----------|----------|-----------------------------|\n| order_id  | INT      | Primary key.                |\n| order_date| DATE     | Date the order was placed.  |\n\n### Example\n\n**Input — orders**\n\n| order_id | order_date |\n|----------|------------|\n| 1        | 2025-01-01 |\n| 2        | 2025-01-01 |\n| 3        | 2025-01-02 |\n\n**Output**\n\n| order_date | order_count |\n|------------|-------------|\n| 2025-01-01 | 2           |\n| 2025-01-02 | 1           |",
    "correctQuery": "SELECT order_date, COUNT(order_id) AS order_count FROM orders GROUP BY order_date ORDER BY order_date ASC;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, order_date DATE);\nINSERT INTO orders (order_id, order_date) VALUES (1, '2025-01-01');\nINSERT INTO orders (order_id, order_date) VALUES (2, '2025-01-01');\nINSERT INTO orders (order_id, order_date) VALUES (3, '2025-01-02');",
    "hints": ["Use GROUP BY on the order_date column."]
  },
  {
    "id": 8,
    "title": "Latest Order per Customer",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given an `orders` table. For each customer, find their **most recent order**.\nReturn `customer_id`, `order_id`, and `order_date` for the latest order of each customer.\n\n### Table: `orders`\n\n| Column      | Type     | Description                  |\n|------------|----------|-----------------------------|\n| order_id   | INT      | Primary key.                |\n| customer_id| INT      | ID of the customer.         |\n| order_date | DATE     | Date the order was placed.  |\n\n### Example\n\n**Input — orders**\n\n| order_id | customer_id | order_date |\n|----------|-------------|------------|\n| 1        | 10          | 2025-01-01 |\n| 2        | 10          | 2025-01-05 |\n| 3        | 11          | 2025-01-03 |\n\n**Output**\n\n| customer_id | order_id | order_date |\n|-------------|----------|------------|\n| 10          | 2        | 2025-01-05 |\n| 11          | 3        | 2025-01-03 |",
    "correctQuery": "WITH RankedOrders AS (SELECT customer_id, order_id, order_date, ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY order_date DESC) as rn FROM orders) SELECT customer_id, order_id, order_date FROM RankedOrders WHERE rn = 1 ORDER BY customer_id;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, customer_id INT, order_date DATE);\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (1, 10, '2025-01-01');\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (2, 10, '2025-01-05');\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (3, 11, '2025-01-03');",
    "hints": ["Use ROW_NUMBER() partitioned by customer_id and ordered by date descending to find the latest."]
  },
  {
    "id": 9,
    "title": "City with the Most Customers",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given a `customers` table. Find the city (or cities) that has the **maximum number of customers**.\nReturn `city` and `customer_count` for those cities.\n\n### Table: `customers`\n\n| Column      | Type     | Description      |\n|------------|----------|------------------|\n| customer_id| INT      | Primary key.     |\n| name       | VARCHAR  | Customer name.   |\n| city       | VARCHAR  | City name.       |\n\n### Example\n\n**Input — customers**\n\n| customer_id | name   | city     |\n|-------------|--------|----------|\n| 1           | Alice  | Seattle  |\n| 2           | Bob    | Boston   |\n| 3           | Carol  | Seattle  |\n\n**Output**\n\n| city    | customer_count |\n|---------|----------------|\n| Seattle | 2              |",
    "correctQuery": "WITH CityCounts AS (SELECT city, COUNT(customer_id) AS customer_count FROM customers GROUP BY city) SELECT city, customer_count FROM CityCounts WHERE customer_count = (SELECT MAX(customer_count) FROM CityCounts);",
    "sourceTableQuery": "CREATE TABLE customers (customer_id INT PRIMARY KEY, name VARCHAR(255), city VARCHAR(255));\nINSERT INTO customers (customer_id, name, city) VALUES (1, 'Alice', 'Seattle');\nINSERT INTO customers (customer_id, name, city) VALUES (2, 'Bob', 'Boston');\nINSERT INTO customers (customer_id, name, city) VALUES (3, 'Carol', 'Seattle');",
    "hints": ["Group by city to count customers first, then filter for the maximum count."]
  },
  {
    "id": 10,
    "title": "Products Never Sold",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given `products` and `order_items` tables. Find all products that have **never been sold** in any order.\nReturn `product_id` and `name`, sorted by `product_id`.\n\n### Table: `products`\n\n| Column     | Type    | Description        |\n|-----------|---------|--------------------|\n| product_id| INT     | Primary key.       |\n| name      | VARCHAR | Product name.      |\n\n### Table: `order_items`\n\n| Column      | Type    | Description                          |\n|------------|---------|-------------------------------------|\n| order_id   | INT     | Order identifier.                   |\n| product_id | INT     | Foreign key to `products`.          |\n| quantity   | INT     | Quantity of this product in order.  |\n\n### Example\n\n**Input — products**\n\n| product_id | name      |\n|-----------|----------|\n| 1         | Keyboard |\n| 2         | Mouse    |\n| 3         | Monitor  |\n\n**Input — order_items**\n\n| order_id | product_id | quantity |\n|----------|------------|----------|\n| 101      | 1          | 2        |\n| 102      | 2          | 1        |\n\n**Output**\n\n| product_id | name    |\n|-----------|---------|\n| 3         | Monitor |",
    "correctQuery": "SELECT p.product_id, p.name FROM products p LEFT JOIN order_items oi ON p.product_id = oi.product_id WHERE oi.product_id IS NULL ORDER BY p.product_id;",
    "sourceTableQuery": "CREATE TABLE products (product_id INT PRIMARY KEY, name VARCHAR(255));\nINSERT INTO products (product_id, name) VALUES (1, 'Keyboard');\nINSERT INTO products (product_id, name) VALUES (2, 'Mouse');\nINSERT INTO products (product_id, name) VALUES (3, 'Monitor');\nCREATE TABLE order_items (order_id INT, product_id INT, quantity INT);\nINSERT INTO order_items (order_id, product_id, quantity) VALUES (101, 1, 2);\nINSERT INTO order_items (order_id, product_id, quantity) VALUES (102, 2, 1);",
    "hints": ["Use a LEFT JOIN to include all products, then filter where the order_items side is NULL."]
  },
  {
    "id": 11,
    "title": "Monthly Revenue by Category",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given `products`, `orders`, and `order_items` tables. Each order item contains quantity and unit price.\nCompute the total revenue per product category per month (YYYY-MM).\nReturn `month`, `category`, and `total_revenue`, sorted by `month` then `category`.\n\n### Table: `products`\n\n| Column     | Type    | Description        |\n|-----------|---------|--------------------|\n| product_id| INT     | Primary key.       |\n| name      | VARCHAR | Product name.      |\n| category  | VARCHAR | Category name.     |\n\n### Table: `orders`\n\n| Column     | Type     | Description                  |\n|-----------|----------|-----------------------------|\n| order_id  | INT      | Primary key.                |\n| order_date| DATE     | Date the order was placed.  |\n\n### Table: `order_items`\n\n| Column      | Type     | Description                          |\n|------------|----------|--------------------------------------|\n| order_id   | INT      | Foreign key to `orders`.             |\n| product_id | INT      | Foreign key to `products`.           |\n| quantity   | INT      | Quantity purchased.                  |\n| unit_price | DECIMAL  | Price per unit at time of purchase.  |\n\n### Requirement\n\nRevenue for a row = `quantity * unit_price`. Group by year-month and category.",
    "correctQuery": "SELECT strftime('%Y-%m', o.order_date) AS month, p.category, SUM(oi.quantity * oi.unit_price) AS total_revenue FROM orders o JOIN order_items oi ON o.order_id = oi.order_id JOIN products p ON oi.product_id = p.product_id GROUP BY 1, 2 ORDER BY month, category;",
    "sourceTableQuery": "CREATE TABLE products (product_id INT PRIMARY KEY, name VARCHAR(255), category VARCHAR(255));\nINSERT INTO products (product_id, name, category) VALUES (1, 'Laptop', 'Electronics');\nINSERT INTO products (product_id, name, category) VALUES (2, 'T-Shirt', 'Apparel');\nCREATE TABLE orders (order_id INT PRIMARY KEY, order_date DATE);\nINSERT INTO orders (order_id, order_date) VALUES (101, '2025-03-15');\nINSERT INTO orders (order_id, order_date) VALUES (102, '2025-03-20');\nINSERT INTO orders (order_id, order_date) VALUES (103, '2025-04-01');\nCREATE TABLE order_items (order_id INT, product_id INT, quantity INT, unit_price DECIMAL(10,2));\nINSERT INTO order_items (order_id, product_id, quantity, unit_price) VALUES (101, 1, 1, 1000.00);\nINSERT INTO order_items (order_id, product_id, quantity, unit_price) VALUES (102, 2, 2, 25.00);\nINSERT INTO order_items (order_id, product_id, quantity, unit_price) VALUES (103, 1, 1, 950.00);",
    "hints": ["Use strftime('%Y-%m', date) to extract the month format."]
  },
  {
    "id": 12,
    "title": "Second Highest Salary",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given an `employees` table. Write a query to find the **second highest distinct salary** in the company.\nIf there is no second highest salary, return `NULL` as `second_highest`.\n\n### Table: `employees`\n\n| Column  | Type    | Description       |\n|--------|---------|-------------------|\n| emp_id | INT     | Primary key.      |\n| name   | VARCHAR | Employee name.    |\n| salary | INT     | Monthly salary.   |\n\n### Output\n\nReturn a single row:\n\n| second_highest |\n|----------------|\n| 7000           |\n\n…or `NULL` if not applicable.",
    "correctQuery": "SELECT (SELECT DISTINCT salary FROM employees ORDER BY salary DESC LIMIT 1 OFFSET 1) AS second_highest;",
    "sourceTableQuery": "CREATE TABLE employees (emp_id INT PRIMARY KEY, name VARCHAR(255), salary INT);\nINSERT INTO employees (emp_id, name, salary) VALUES (1, 'Alice', 10000);\nINSERT INTO employees (emp_id, name, salary) VALUES (2, 'Bob', 7000);\nINSERT INTO employees (emp_id, name, salary) VALUES (3, 'Carol', 7000);\nINSERT INTO employees (emp_id, name, salary) VALUES (4, 'David', 5000);",
    "hints": ["Use LIMIT 1 OFFSET 1 to skip the highest salary."]
  },
  {
    "id": 13,
    "title": "Consecutive Login Days",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given a `logins` table with the days users logged in.\nFor each user, find the length of their **longest streak** of consecutive login days.\n\n### Table: `logins`\n\n| Column     | Type | Description                   |\n|-----------|------|-------------------------------|\n| user_id   | INT  | ID of the user.               |\n| login_date| DATE | Date user logged in.          |\n\n### Requirements\n\nReturn `user_id` and `max_streak`, where `max_streak` is the maximum number of consecutive days they logged in.\nUse window functions or date arithmetic to detect consecutive days.",
    "correctQuery": "WITH DateGrouped AS (SELECT user_id, login_date, julianday(login_date) - ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) AS date_group FROM logins), StreakLengths AS (SELECT user_id, COUNT(login_date) AS streak_length FROM DateGrouped GROUP BY user_id, date_group) SELECT user_id, MAX(streak_length) AS max_streak FROM StreakLengths GROUP BY user_id;",
    "sourceTableQuery": "CREATE TABLE logins (user_id INT, login_date DATE);\nINSERT INTO logins (user_id, login_date) VALUES (1, '2025-01-01');\nINSERT INTO logins (user_id, login_date) VALUES (1, '2025-01-02');\nINSERT INTO logins (user_id, login_date) VALUES (1, '2025-01-04');\nINSERT INTO logins (user_id, login_date) VALUES (2, '2025-01-01');\nINSERT INTO logins (user_id, login_date) VALUES (2, '2025-01-02');\nINSERT INTO logins (user_id, login_date) VALUES (2, '2025-01-03');\nINSERT INTO logins (user_id, login_date) VALUES (2, '2025-01-05');",
    "hints": ["Try subtracting the ROW_NUMBER() from the date to group consecutive sequences."]
  },
  {
    "id": 14,
    "title": "Top 3 Products Per Category",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given `products` and `order_items` tables. For each category, find the **top 3 products** by total quantity sold.\nIf a category has fewer than 3 products, return all of them.\n\n### Table: `products`\n\n| Column     | Type    | Description    |\n|-----------|---------|----------------|\n| product_id| INT     | Primary key.   |\n| name      | VARCHAR | Product name.  |\n| category  | VARCHAR | Category name. |\n\n### Table: `order_items`\n\n| Column      | Type | Description                          |\n|------------|------|------------------------------------|\n| order_id   | INT  | Order identifier.                   |\n| product_id | INT  | Foreign key to `products`.          |\n| quantity   | INT  | Quantity of this product in order. |\n\n### Requirements\n\nReturn `category`, `product_id`, `name`, and `total_quantity`, sorted by `category` then `total_quantity` descending.\nUse a window function like `ROW_NUMBER()` partitioned by category.",
    "correctQuery": "WITH ProductSales AS (SELECT p.category, p.product_id, p.name, SUM(oi.quantity) AS total_quantity FROM products p JOIN order_items oi ON p.product_id = oi.product_id GROUP BY 1, 2, 3), RankedSales AS (SELECT category, product_id, name, total_quantity, DENSE_RANK() OVER (PARTITION BY category ORDER BY total_quantity DESC) AS sales_rank FROM ProductSales) SELECT category, product_id, name, total_quantity FROM RankedSales WHERE sales_rank <= 3 ORDER BY category, total_quantity DESC;",
    "sourceTableQuery": "CREATE TABLE products (product_id INT PRIMARY KEY, name VARCHAR(255), category VARCHAR(255));\nINSERT INTO products (product_id, name, category) VALUES (1, 'A', 'Electronics');\nINSERT INTO products (product_id, name, category) VALUES (2, 'B', 'Electronics');\nINSERT INTO products (product_id, name, category) VALUES (3, 'C', 'Electronics');\nINSERT INTO products (product_id, name, category) VALUES (4, 'D', 'Apparel');\nCREATE TABLE order_items (order_id INT, product_id INT, quantity INT);\nINSERT INTO order_items (order_id, product_id, quantity) VALUES (101, 1, 10);\nINSERT INTO order_items (order_id, product_id, quantity) VALUES (101, 2, 5);\nINSERT INTO order_items (order_id, product_id, quantity) VALUES (102, 3, 15);\nINSERT INTO order_items (order_id, product_id, quantity) VALUES (103, 4, 20);",
    "hints": ["Use DENSE_RANK() or RANK() partitioned by category to rank products based on sales."]
  },
  {
    "id": 15,
    "title": "Users Who Ordered All Categories",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given `users`, `orders`, `order_items`, and `products` tables.\nFind users who have ordered **at least one product from every category** that exists in the `products` table.\n\n### Table: `users`\n\n| Column  | Type    | Description  |\n|--------|---------|--------------|\n| user_id| INT     | Primary key. |\n| name   | VARCHAR | User name.   |\n\n### Table: `orders`\n\n| Column     | Type | Description             |\n|-----------|------|-------------------------|\n| order_id  | INT  | Primary key.            |\n| user_id   | INT  | Foreign key to `users`. |\n\n### Table: `order_items`\n\n| Column      | Type | Description                          |\n|------------|------|------------------------------------|\n| order_id   | INT  | Foreign key to `orders`.            |\n| product_id | INT  | Foreign key to `products`.          |\n\n### Table: `products`\n\n| Column     | Type    | Description    |\n|-----------|---------|----------------|\n| product_id| INT     | Primary key.   |\n| category  | VARCHAR | Category name. |\n\n### Requirements\n\nReturn `user_id` and `name` of users who have purchased from **all categories**.",
    "correctQuery": "SELECT u.user_id, u.name FROM users u JOIN orders o ON u.user_id = o.user_id JOIN order_items oi ON o.order_id = oi.order_id JOIN products p ON oi.product_id = p.product_id GROUP BY u.user_id, u.name HAVING COUNT(DISTINCT p.category) = (SELECT COUNT(DISTINCT category) FROM products);",
    "sourceTableQuery": "CREATE TABLE users (user_id INT PRIMARY KEY, name VARCHAR(255));\nINSERT INTO users (user_id, name) VALUES (101, 'Alice');\nINSERT INTO users (user_id, name) VALUES (102, 'Bob');\nCREATE TABLE products (product_id INT PRIMARY KEY, category VARCHAR(255));\nINSERT INTO products (product_id, category) VALUES (1, 'Electronics');\nINSERT INTO products (product_id, category) VALUES (2, 'Apparel');\nCREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT);\nINSERT INTO orders (order_id, user_id) VALUES (1001, 101);\nINSERT INTO orders (order_id, user_id) VALUES (1002, 102);\nCREATE TABLE order_items (order_id INT, product_id INT);\nINSERT INTO order_items (order_id, product_id) VALUES (1001, 1);\nINSERT INTO order_items (order_id, product_id) VALUES (1001, 2);\nINSERT INTO order_items (order_id, product_id) VALUES (1002, 1);",
    "hints": ["Compare the distinct count of categories a user purchased with the total distinct count of categories in the products table."]
  },
  {
    "id": 16,
    "title": "Employees Without a Manager",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given an `employees` table where some employees have managers.\nFind employees that **do not have a manager** (their `manager_id` is `NULL` or does not correspond to any existing employee).\n\n### Table: `employees`\n\n| Column      | Type     | Description                             |\n|-----------|---------|-----------------------------------------|\n| emp_id    | INT     | Primary key.                            |\n| name      | VARCHAR | Employee name.                          |\n| manager_id| INT     | Employee ID of their manager, nullable. |\n\n### Requirements\n\nReturn `emp_id` and `name` for such employees, sorted by `emp_id`.",
    "correctQuery": "SELECT e.emp_id, e.name FROM employees e LEFT JOIN employees m ON e.manager_id = m.emp_id WHERE e.manager_id IS NULL OR m.emp_id IS NULL ORDER BY e.emp_id;",
    "sourceTableQuery": "CREATE TABLE employees (emp_id INT PRIMARY KEY, name VARCHAR(255), manager_id INT);\nINSERT INTO employees (emp_id, name, manager_id) VALUES (100, 'CEO Bob', NULL);\nINSERT INTO employees (emp_id, name, manager_id) VALUES (101, 'Manager Jane', 100);\nINSERT INTO employees (emp_id, name, manager_id) VALUES (102, 'Employee Mike', 101);\nINSERT INTO employees (emp_id, name, manager_id) VALUES (103, 'Unmanaged Carol', 999); -- Manager 999 does not exist",
    "hints": ["Use a LEFT JOIN on the employees table to itself to check if the manager_id exists."]
  },
  {
    "id": 17,
    "title": "Running Total of Daily Sales",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given a `sales` table where each row represents one sale.\nCompute the **running total** of sales amount per day when ordered by date.\n\n### Table: `sales`\n\n| Column   | Type     | Description         |\n|---------|----------|---------------------|\n| sale_id | INT      | Primary key.        |\n| sale_date | DATE   | Date of the sale.   |\n| amount  | DECIMAL  | Amount of the sale. |\n\n### Requirements\n\nFor each `sale_date`, compute total sales that day, then compute a cumulative sum over dates.\nReturn `sale_date`, `daily_amount`, and `running_total`, sorted by `sale_date`.",
    "correctQuery": "WITH DailySales AS (SELECT sale_date, SUM(amount) AS daily_amount FROM sales GROUP BY sale_date) SELECT sale_date, daily_amount, SUM(daily_amount) OVER (ORDER BY sale_date) AS running_total FROM DailySales ORDER BY sale_date;",
    "sourceTableQuery": "CREATE TABLE sales (sale_id INT PRIMARY KEY, sale_date DATE, amount DECIMAL(10,2));\nINSERT INTO sales (sale_id, sale_date, amount) VALUES (1, '2025-01-01', 10.00);\nINSERT INTO sales (sale_id, sale_date, amount) VALUES (2, '2025-01-01', 5.00);\nINSERT INTO sales (sale_id, sale_date, amount) VALUES (3, '2025-01-02', 20.00);\nINSERT INTO sales (sale_id, sale_date, amount) VALUES (4, '2025-01-03', 15.00);",
    "hints": ["First aggregate sales by date, then use a window function with SUM() OVER (ORDER BY date)."]
  },
  {
    "id": 18,
    "title": "Customers with Decreasing Spend",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given an `orders` table. For each customer, consider their orders in chronological order.\nFind customers whose **order amounts strictly decrease** on every subsequent order.\n\n### Table: `orders`\n\n| Column      | Type     | Description         |\n|------------|----------|---------------------|\n| order_id   | INT      | Primary key.        |\n| customer_id| INT      | Customer ID.        |\n| order_date | DATE     | Date of the order.  |\n| amount     | DECIMAL  | Order amount.       |\n\n### Requirements\n\nReturn `customer_id` for customers whose sequence of `amount` is strictly decreasing over time.\nUse window functions to compare each order with the previous one.",
    "correctQuery": "WITH RankedOrders AS (SELECT *, LAG(amount, 1, 999999999) OVER (PARTITION BY customer_id ORDER BY order_date, order_id) AS prev_amount FROM orders), DecreasingCheck AS (SELECT customer_id, (CASE WHEN amount < prev_amount THEN 0 ELSE 1 END) AS is_non_decreasing FROM RankedOrders) SELECT DISTINCT customer_id FROM DecreasingCheck GROUP BY customer_id HAVING SUM(is_non_decreasing) = 0;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, customer_id INT, order_date DATE, amount DECIMAL(10,2));\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (1, 101, '2025-01-01', 100.00);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (2, 101, '2025-01-10', 80.00);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (3, 102, '2025-01-05', 50.00);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (4, 102, '2025-01-15', 50.00); -- Not decreasing",
    "hints": ["Use LAG() to compare the current order amount with the previous one for each customer."]
  },
  {
    "id": 19,
    "title": "Median Salary per Department",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given an `employees` table. For each department, compute the **median salary**.\n\n### Table: `employees`\n\n| Column      | Type    | Description         |\n|------------|---------|---------------------|\n| emp_id     | INT     | Primary key.        |\n| department | VARCHAR | Department name.    |\n| salary     | INT     | Monthly salary.     |\n\n### Requirements\n\nUse window functions (like `PERCENTILE_CONT` or manual ranking) to compute the median.\nReturn `department` and `median_salary`.",
    "correctQuery": "WITH RankedSalaries AS (SELECT department, salary, ROW_NUMBER() OVER (PARTITION BY department ORDER BY salary) AS rn, COUNT(*) OVER (PARTITION BY department) AS count_dept FROM employees) SELECT department, AVG(salary) AS median_salary FROM RankedSalaries WHERE rn IN ((count_dept + 1) / 2, (count_dept + 2) / 2) GROUP BY department;",
    "sourceTableQuery": "CREATE TABLE employees (emp_id INT PRIMARY KEY, department VARCHAR(255), salary INT);\nINSERT INTO employees (emp_id, department, salary) VALUES (1, 'IT', 60000);\nINSERT INTO employees (emp_id, department, salary) VALUES (2, 'IT', 70000);\nINSERT INTO employees (emp_id, department, salary) VALUES (3, 'IT', 80000);\nINSERT INTO employees (emp_id, department, salary) VALUES (4, 'HR', 40000);\nINSERT INTO employees (emp_id, department, salary) VALUES (5, 'HR', 50000);\nINSERT INTO employees (emp_id, department, salary) VALUES (6, 'HR', 60000);",
    "hints": ["Since SQLite lacks a Median function, filter rows where the rank is equal to the middle index(es)."]
  },
  {
    "id": 20,
    "title": "Daily Active Users",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given an `events` table that records user actions in an app.\nFor each day, compute the number of **distinct active users**.\n\n### Table: `events`\n\n| Column      | Type    | Description                      |\n|------------|---------|----------------------------------|\n| user_id    | INT     | ID of the user.                  |\n| event_date | DATE    | Date of the event.               |\n| event_type | VARCHAR | Type of event (login, click, etc.)|\n\n### Requirements\n\nReturn `event_date` and `active_users` (count of distinct `user_id`), sorted by `event_date`.",
    "correctQuery": "SELECT event_date, COUNT(DISTINCT user_id) AS active_users FROM events GROUP BY event_date ORDER BY event_date;",
    "sourceTableQuery": "CREATE TABLE events (user_id INT, event_date DATE, event_type VARCHAR(50));\nINSERT INTO events (user_id, event_date, event_type) VALUES (10, '2025-01-01', 'login');\nINSERT INTO events (user_id, event_date, event_type) VALUES (20, '2025-01-01', 'click');\nINSERT INTO events (user_id, event_date, event_type) VALUES (10, '2025-01-01', 'view');\nINSERT INTO events (user_id, event_date, event_type) VALUES (30, '2025-01-02', 'login');\nINSERT INTO events (user_id, event_date, event_type) VALUES (10, '2025-01-02', 'login');",
    "hints": ["Use COUNT(DISTINCT user_id) to ensure each user is only counted once per day."]
  },
  {
    "id": 21,
    "title": "User Cohort Retention",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given a `signups` table and a `logins` table.\nDefine a cohort as all users who signed up in the same **month** (YYYY-MM).\nFor each cohort month and each of the next three months, compute how many users logged in at least once.\n\n### Table: `signups`\n\n| Column      | Type | Description              |\n|------------|------|--------------------------|\n| user_id    | INT  | Primary key.             |\n| signup_date| DATE | Date user signed up.     |\n\n### Table: `logins`\n\n| Column      | Type | Description             |\n|------------|------|-------------------------|\n| user_id    | INT  | ID of the user.         |\n| login_date | DATE | Date user logged in.    |\n\n### Requirements\n\nFor each `cohort_month` (from `signup_date`) and `month_offset` in {0,1,2,3}, return how many users from that cohort logged in during that month (cohort month + offset).",
    "correctQuery": "WITH Cohorts AS (SELECT user_id, strftime('%Y-%m', signup_date) AS cohort_month FROM signups), LoginMonths AS (SELECT DISTINCT user_id, strftime('%Y-%m', login_date) AS login_month FROM logins), CohortActivity AS (SELECT c.cohort_month, l.login_month, c.user_id FROM Cohorts c JOIN LoginMonths l ON c.user_id = l.user_id), Calendar AS (SELECT DISTINCT cohort_month, strftime('%Y-%m', date(cohort_month || '-01', '+' || CAST(T.value AS TEXT) || ' month')) AS expected_month, T.value AS month_offset FROM Cohorts, (SELECT 0 AS value UNION ALL SELECT 1 UNION ALL SELECT 2 UNION ALL SELECT 3) AS T) SELECT c.cohort_month, cal.month_offset, COUNT(c.user_id) AS active_users FROM Calendar cal LEFT JOIN CohortActivity c ON cal.cohort_month = c.cohort_month AND cal.expected_month = c.login_month GROUP BY 1, 2 ORDER BY 1, 2;",
    "sourceTableQuery": "CREATE TABLE signups (user_id INT PRIMARY KEY, signup_date DATE);\nINSERT INTO signups (user_id, signup_date) VALUES (1, '2024-01-10');\nINSERT INTO signups (user_id, signup_date) VALUES (2, '2024-01-20');\nINSERT INTO signups (user_id, signup_date) VALUES (3, '2024-02-05');\nCREATE TABLE logins (user_id INT, login_date DATE);\nINSERT INTO logins (user_id, login_date) VALUES (1, '2024-01-15');\nINSERT INTO logins (user_id, login_date) VALUES (1, '2024-02-15');\nINSERT INTO logins (user_id, login_date) VALUES (2, '2024-01-25');\nINSERT INTO logins (user_id, login_date) VALUES (3, '2024-03-01');",
    "hints": ["First, extract the month from signup_date to create cohorts.", "Generate a calendar of offsets (0, 1, 2, 3) and LEFT JOIN your activity data to it to ensure zero counts appear."]
  },
  {
    "id": 22,
    "title": "Employee Hierarchy Depth",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given an `employees` table representing an organization tree.\nEach employee may have a `manager_id` that points to another `emp_id`. Top-level employees have `NULL` manager.\nFind the **maximum depth** of the hierarchy.\n\n### Table: `employees`\n\n| Column     | Type    | Description                        |\n|-----------|---------|------------------------------------|\n| emp_id    | INT     | Primary key.                       |\n| name      | VARCHAR | Employee name.                     |\n| manager_id| INT     | ID of manager, or NULL.            |\n\n### Requirements\n\nUse a recursive CTE to compute the depth of each node.\nReturn a single row with:\n\n| max_depth |\n|-----------|\n| 4         |",
    "correctQuery": "WITH RECURSIVE Hierarchy AS (SELECT emp_id, name, manager_id, 1 AS level FROM employees WHERE manager_id IS NULL UNION ALL SELECT e.emp_id, e.name, e.manager_id, h.level + 1 FROM employees e JOIN Hierarchy h ON e.manager_id = h.emp_id) SELECT MAX(level) AS max_depth FROM Hierarchy;",
    "sourceTableQuery": "CREATE TABLE employees (emp_id INT PRIMARY KEY, name VARCHAR(255), manager_id INT);\nINSERT INTO employees (emp_id, name, manager_id) VALUES (1, 'CEO', NULL);\nINSERT INTO employees (emp_id, name, manager_id) VALUES (2, 'Director', 1);\nINSERT INTO employees (emp_id, name, manager_id) VALUES (3, 'Manager', 2);\nINSERT INTO employees (emp_id, name, manager_id) VALUES (4, 'Senior Dev', 3);\nINSERT INTO employees (emp_id, name, manager_id) VALUES (5, 'Junior Dev', 4);",
    "hints": ["Use a Recursive CTE starting with employees who have no manager.", "Increment a 'level' counter in the recursive step."]
  },
  {
    "id": 23,
    "title": "Detect Cycles in Follow Graph",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given a `follows` table representing a directed graph of user follows.\nDetect whether there exists any **cycle** in the graph.\n\n### Table: `follows`\n\n| Column   | Type | Description                      |\n|---------|------|----------------------------------|\n| follower| INT  | User who follows.                |\n| followee| INT  | User being followed.             |\n\n### Requirements\n\nReturn a single row:\n\n| has_cycle |\n|-----------|\n| 1         |\n\nif any directed cycle exists, otherwise 0.\nThis can be solved using a recursive CTE and cycle detection.",
    "correctQuery": "WITH RECURSIVE CycleCheck AS (SELECT follower, followee, followee AS path_end FROM follows UNION ALL SELECT cc.follower, f.followee, f.followee AS path_end FROM follows f JOIN CycleCheck cc ON f.follower = cc.followee WHERE f.followee != cc.follower) SELECT CASE WHEN EXISTS (SELECT 1 FROM CycleCheck WHERE follower = path_end) THEN 1 ELSE 0 END AS has_cycle;",
    "sourceTableQuery": "CREATE TABLE follows (follower INT, followee INT);\nINSERT INTO follows (follower, followee) VALUES (1, 2);\nINSERT INTO follows (follower, followee) VALUES (2, 3);\nINSERT INTO follows (follower, followee) VALUES (3, 1); -- Cycle: 1->2->3->1\nINSERT INTO follows (follower, followee) VALUES (4, 5);",
    "hints": ["Track the path of connections using a recursive CTE.", "Check if the end of a path connects back to the start."]
  },
  {
    "id": 24,
    "title": "K-th Highest Salary per Department",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given an `employees` table and a parameter `k`.\nFor each department, find the **k-th highest distinct salary**.\nIf a department has fewer than k distinct salaries, return `NULL` for that department.\n\n### Table: `employees`\n\n| Column      | Type    | Description         |\n|------------|---------|---------------------|\n| emp_id     | INT     | Primary key.        |\n| department | VARCHAR | Department name.    |\n| salary     | INT     | Monthly salary.     |\n\n### Requirements\n\nReturn `department` and `kth_salary`.\nUse window functions with `DENSE_RANK()` partitioned by department.",
    "correctQuery": "WITH RankedSalaries AS (SELECT DISTINCT department, salary, DENSE_RANK() OVER (PARTITION BY department ORDER BY salary DESC) AS salary_rank FROM employees) SELECT department, (SELECT salary FROM RankedSalaries WHERE salary_rank = 2 AND department = T.department LIMIT 1) AS kth_salary FROM (SELECT DISTINCT department FROM employees) AS T ORDER BY department;",
    "sourceTableQuery": "CREATE TABLE employees (emp_id INT PRIMARY KEY, department VARCHAR(255), salary INT);\nINSERT INTO employees (emp_id, department, salary) VALUES (1, 'IT', 90000);\nINSERT INTO employees (emp_id, department, salary) VALUES (2, 'IT', 80000);\nINSERT INTO employees (emp_id, department, salary) VALUES (3, 'IT', 70000);\nINSERT INTO employees (emp_id, department, salary) VALUES (4, 'HR', 60000);\nINSERT INTO employees (emp_id, department, salary) VALUES (5, 'HR', 50000);",
    "hints": ["Use DENSE_RANK() to handle ties in salary rankings.", "You may need a subquery to ensure departments with fewer than K salaries return NULL."]
  },
  {
    "id": 25,
    "title": "Overlapping Reservations",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given a `reservations` table for an online booking system.\nFind all pairs of reservations that **overlap in time** for the same room.\n\n### Table: `reservations`\n\n| Column         | Type     | Description              |\n|---------------|----------|--------------------------|\n| reservation_id| INT      | Primary key.             |\n| room_id       | INT      | ID of the room.          |\n| start_time    | DATETIME | Start of reservation.    |\n| end_time      | DATETIME | End of reservation.      |\n\n### Requirements\n\nReturn `room_id`, `reservation_id_1`, `reservation_id_2` where the time intervals overlap.\nDo not return duplicate pairs (i.e., `(a,b)` and `(b,a)` both).",
    "correctQuery": "SELECT r1.room_id, r1.reservation_id AS reservation_id_1, r2.reservation_id AS reservation_id_2 FROM reservations r1 JOIN reservations r2 ON r1.room_id = r2.room_id AND r1.reservation_id < r2.reservation_id AND r1.start_time < r2.end_time AND r2.start_time < r1.end_time ORDER BY r1.room_id, reservation_id_1, reservation_id_2;",
    "sourceTableQuery": "CREATE TABLE reservations (reservation_id INT PRIMARY KEY, room_id INT, start_time DATETIME, end_time DATETIME);\nINSERT INTO reservations (reservation_id, room_id, start_time, end_time) VALUES (1, 10, '2025-01-01 10:00:00', '2025-01-01 11:00:00');\nINSERT INTO reservations (reservation_id, room_id, start_time, end_time) VALUES (2, 10, '2025-01-01 10:30:00', '2025-01-01 11:30:00'); -- Overlap\nINSERT INTO reservations (reservation_id, room_id, start_time, end_time) VALUES (3, 10, '2025-01-01 12:00:00', '2025-01-01 13:00:00');\nINSERT INTO reservations (reservation_id, room_id, start_time, end_time) VALUES (4, 20, '2025-01-01 10:00:00', '2025-01-01 11:00:00');",
    "hints": ["Two time intervals [A,B] and [C,D] overlap if A < D and C < B.", "Use a self-join on the reservations table to find matching pairs."]
  },
  {
    "id": 26,
    "title": "Windowed Order Rank per Customer",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given an `orders` table. For each customer, rank their orders by amount within a 30-day rolling window.\n\n### Table: `orders`\n\n| Column      | Type     | Description         |\n|------------|----------|---------------------|\n| order_id   | INT      | Primary key.        |\n| customer_id| INT      | Customer ID.        |\n| order_date | DATE     | Date of the order.  |\n| amount     | DECIMAL  | Order amount.       |\n\n### Requirements\n\nFor each order, consider other orders by the same customer with `order_date` in the 30 days ending at the current `order_date`.\nCompute a rank (`window_rank`) based on amount within that window (highest amount gets rank 1).\nReturn `order_id`, `customer_id`, `order_date`, `amount`, and `window_rank`.",
    "correctQuery": "SELECT order_id, customer_id, order_date, amount, RANK() OVER (PARTITION BY customer_id ORDER BY amount DESC) AS window_rank FROM orders WHERE order_date >= date(order_date, '-30 days') ORDER BY order_id;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, customer_id INT, order_date DATE, amount DECIMAL(10,2));\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (1, 101, '2025-01-01', 100.00);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (2, 101, '2025-01-15', 150.00);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (3, 101, '2025-02-20', 200.00);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (4, 101, '2025-03-01', 50.00); -- Outside 30 day window for order 3",
    "hints": ["This requires advanced window logic or a self-join with a date range condition.", "Filter the self-join using 'date(t2.date) BETWEEN date(t1.date, -30 days) AND t1.date'."]
  },
  {
    "id": 27,
    "title": "Churned Customers",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given a `subscriptions` table recording when customers start and end their subscriptions.\nA customer is considered **churned** in a month if:\n\n1. They had an active subscription at some point before that month, and\n2. They do not have an active subscription on any day of that month or after.\n\n### Table: `subscriptions`\n\n| Column       | Type  | Description                      |\n|-------------|-------|----------------------------------|\n| customer_id | INT   | Customer ID.                     |\n| start_date  | DATE  | Subscription start date.         |\n| end_date    | DATE  | Subscription end date (nullable).|\n\n### Requirements\n\nAssume open-ended subscriptions have `NULL` end_date.\nReturn `customer_id` and `churn_month` (YYYY-MM) when they churned.",
    "correctQuery": "WITH NextSubscription AS (SELECT *, LEAD(start_date) OVER (PARTITION BY customer_id ORDER BY start_date) AS next_start_date FROM subscriptions), PotentialChurns AS (SELECT customer_id, strftime('%Y-%m', date(end_date, '+1 day')) AS churn_month FROM NextSubscription WHERE next_start_date IS NULL OR next_start_date > date(end_date, '+1 day')) SELECT DISTINCT customer_id, churn_month FROM PotentialChurns ORDER BY customer_id, churn_month;",
    "sourceTableQuery": "CREATE TABLE subscriptions (customer_id INT, start_date DATE, end_date DATE);\nINSERT INTO subscriptions (customer_id, start_date, end_date) VALUES (1, '2024-01-01', '2024-01-31');\nINSERT INTO subscriptions (customer_id, start_date, end_date) VALUES (1, '2024-02-01', '2024-02-29');\nINSERT INTO subscriptions (customer_id, start_date, end_date) VALUES (2, '2024-03-01', '2024-03-31');\nINSERT INTO subscriptions (customer_id, start_date, end_date) VALUES (2, '2024-04-15', '2024-05-15'); -- GAP for user 2 in April",
    "hints": ["Use LEAD() to find the next subscription start date for each customer.", "A churn happens if the gap between 'end_date' and 'next_start_date' covers a full month."]
  },
  {
    "id": 28,
    "title": "Lagging and Leading Indicators",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given a `metrics` table storing a numeric business metric per day.\nFor each date, compute the **previous day's value**, **next day's value**, and the 3-day moving average centered on that day.\n\n### Table: `metrics`\n\n| Column | Type     | Description           |\n|--------|----------|-----------------------|\n| m_date| DATE     | Date of the metric.   |\n| value | DECIMAL  | Metric value.         |\n\n### Requirements\n\nReturn `m_date`, `value`, `prev_value`, `next_value`, and `moving_avg_3d`.\nUse `LAG`, `LEAD`, and a window frame for the moving average.",
    "correctQuery": "SELECT m_date, value, LAG(value, 1, NULL) OVER (ORDER BY m_date) AS prev_value, LEAD(value, 1, NULL) OVER (ORDER BY m_date) AS next_value, AVG(value) OVER (ORDER BY m_date ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) AS moving_avg_3d FROM metrics ORDER BY m_date;",
    "sourceTableQuery": "CREATE TABLE metrics (m_date DATE, value DECIMAL(10,2));\nINSERT INTO metrics (m_date, value) VALUES ('2025-01-01', 10.00);\nINSERT INTO metrics (m_date, value) VALUES ('2025-01-02', 20.00);\nINSERT INTO metrics (m_date, value) VALUES ('2025-01-03', 15.00);\nINSERT INTO metrics (m_date, value) VALUES ('2025-01-04', 30.00);",
    "hints": ["Use LAG() and LEAD() for the previous and next values.", "For the moving average, define a window frame: ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING."]
  },
  {
    "id": 29,
    "title": "Bid-Ask Spread by Minute",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given a `quotes` table with bid and ask prices for a stock at different timestamps.\nCompute the **average bid-ask spread** per minute.\n\n### Table: `quotes`\n\n| Column   | Type      | Description              |\n|---------|-----------|--------------------------|\n| q_time  | DATETIME  | Timestamp of the quote.  |\n| bid     | DECIMAL   | Bid price.               |\n| ask     | DECIMAL   | Ask price.               |\n\n### Requirements\n\nFor each minute (YYYY-MM-DD HH:MM), compute the average `(ask - bid)`.\nReturn `minute` and `avg_spread`, sorted by `minute`.",
    "correctQuery": "SELECT strftime('%Y-%m-%d %H:%M', q_time) AS minute, ROUND(AVG(ask - bid), 4) AS avg_spread FROM quotes GROUP BY 1 ORDER BY 1;",
    "sourceTableQuery": "CREATE TABLE quotes (q_time DATETIME, bid DECIMAL(10,4), ask DECIMAL(10,4));\nINSERT INTO quotes (q_time, bid, ask) VALUES ('2025-01-01 09:30:10', 100.00, 100.05);\nINSERT INTO quotes (q_time, bid, ask) VALUES ('2025-01-01 09:30:20', 100.10, 100.15);\nINSERT INTO quotes (q_time, bid, ask) VALUES ('2025-01-01 09:31:05', 100.20, 100.30);",
    "hints": ["Truncate the timestamp to minutes using strftime().", "Group by this minute string and compute AVG(ask - bid)."]
  },
  {
    "id": 30,
    "title": "Detect Anomalous Transactions",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given a `transactions` table.\nFor each user, compute the average and standard deviation of their transaction amounts.\nMark a transaction as **anomalous** if its amount is more than 3 standard deviations above the user's mean.\n\n### Table: `transactions`\n\n| Column      | Type    | Description         |\n|------------|---------|---------------------|\n| txn_id     | INT     | Primary key.        |\n| user_id    | INT     | User ID.            |\n| txn_date   | DATE    | Date of transaction.|\n| amount     | DECIMAL | Transaction amount. |\n\n### Requirements\n\nReturn `txn_id`, `user_id`, `amount`, and a flag column `is_anomalous` (0 or 1).\nUse window aggregates for mean and standard deviation per user.",
    "correctQuery": "WITH UserStats AS (SELECT *, AVG(amount) OVER (PARTITION BY user_id) AS mean_amount, SQRT(AVG(amount * amount) OVER (PARTITION BY user_id) - AVG(amount) OVER (PARTITION BY user_id) * AVG(amount) OVER (PARTITION BY user_id)) AS std_dev FROM transactions) SELECT txn_id, user_id, amount, CASE WHEN amount > mean_amount + (3 * std_dev) THEN 1 ELSE 0 END AS is_anomalous FROM UserStats ORDER BY txn_id;",
    "sourceTableQuery": "CREATE TABLE transactions (txn_id INT PRIMARY KEY, user_id INT, txn_date DATE, amount DECIMAL(10,2));\nINSERT INTO transactions (txn_id, user_id, txn_date, amount) VALUES (1, 101, '2025-01-01', 50.00);\nINSERT INTO transactions (txn_id, user_id, txn_date, amount) VALUES (2, 101, '2025-01-02', 55.00);\nINSERT INTO transactions (txn_id, user_id, txn_date, amount) VALUES (3, 101, '2025-01-03', 900.00); -- Anomaly\nINSERT INTO transactions (txn_id, user_id, txn_date, amount) VALUES (4, 102, '2025-01-01', 10.00);\nINSERT INTO transactions (txn_id, user_id, txn_date, amount) VALUES (5, 102, '2025-01-02', 12.00);",
    "hints": ["Calculate the mean and standard deviation using window functions partitioned by user.", "SQLite doesn't have a STDDEV() function, so you must calculate it manually: SQRT(AVG(x*x) - AVG(x)*AVG(x))."]
  },
  {
    "id": 31,
    "title": "Filter High Value Orders",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given an `orders` table. Write a query to return all orders where the `amount` is **greater than or equal to 100**.\nReturn all columns, sorted by `order_id`.\n\n### Table: `orders`\n\n| Column      | Type     | Description         |\n|------------|----------|---------------------|\n| order_id   | INT      | Primary key.        |\n| customer_id| INT      | Customer ID.        |\n| order_date | DATE     | Date of the order.  |\n| amount     | DECIMAL  | Order amount.       |\n",
    "correctQuery": "SELECT * FROM orders WHERE amount >= 100 ORDER BY order_id;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, customer_id INT, order_date DATE, amount DECIMAL(10,2));\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (1, 101, '2025-01-01', 50.00);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (2, 102, '2025-01-05', 120.00);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (3, 101, '2025-01-08', 99.99);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (4, 103, '2025-01-10', 150.00);",
    "hints": ["Use a WHERE clause to filter by amount >= 100."]
  },
  {
    "id": 32,
    "title": "Customers by Registration Year",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given a `customers` table. For each **registration year**, count how many customers signed up.\nReturn `signup_year` and `customer_count`, sorted by `signup_year`.\n\n### Table: `customers`\n\n| Column       | Type   | Description              |\n|-------------|--------|--------------------------|\n| customer_id | INT    | Primary key.             |\n| name        | VARCHAR| Customer name.           |\n| signup_date | DATE   | Date the customer joined |",
    "correctQuery": "SELECT strftime('%Y', signup_date) AS signup_year, COUNT(customer_id) AS customer_count FROM customers GROUP BY signup_year ORDER BY signup_year;",
    "sourceTableQuery": "CREATE TABLE customers (customer_id INT PRIMARY KEY, name VARCHAR(255), signup_date DATE);\nINSERT INTO customers (customer_id, name, signup_date) VALUES (1, 'Alice', '2024-05-15');\nINSERT INTO customers (customer_id, name, signup_date) VALUES (2, 'Bob', '2024-08-01');\nINSERT INTO customers (customer_id, name, signup_date) VALUES (3, 'Carol', '2025-01-10');\nINSERT INTO customers (customer_id, name, signup_date) VALUES (4, 'David', '2025-03-20');",
    "hints": ["Use strftime('%Y', signup_date) to extract the year."]
  },
  {
    "id": 33,
    "title": "Products by Category Count",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given a `products` table. Count how many products belong to each category.\nReturn `category` and `product_count`, sorted by `product_count` descending, then `category` ascending.\n\n### Table: `products`\n\n| Column     | Type    | Description    |\n|-----------|---------|----------------|\n| product_id| INT     | Primary key.   |\n| name      | VARCHAR | Product name.  |\n| category  | VARCHAR | Category name. |",
    "correctQuery": "SELECT category, COUNT(product_id) AS product_count FROM products GROUP BY category ORDER BY product_count DESC, category ASC;",
    "sourceTableQuery": "CREATE TABLE products (product_id INT PRIMARY KEY, name VARCHAR(255), category VARCHAR(255));\nINSERT INTO products (product_id, name, category) VALUES (1, 'Phone', 'Electronics');\nINSERT INTO products (product_id, name, category) VALUES (2, 'Tablet', 'Electronics');\nINSERT INTO products (product_id, name, category) VALUES (3, 'Socks', 'Apparel');\nINSERT INTO products (product_id, name, category) VALUES (4, 'Shirt', 'Apparel');\nINSERT INTO products (product_id, name, category) VALUES (5, 'Pants', 'Apparel');",
    "hints": ["Use GROUP BY category and count the rows."]
  },
  {
    "id": 34,
    "title": "Orders in a Date Range",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given an `orders` table. Return all orders where `order_date` is between **2025-01-01** and **2025-01-31** inclusive.\nReturn `order_id`, `customer_id`, and `order_date`, sorted by `order_date`.\n\n### Table: `orders`\n\n| Column      | Type     | Description         |\n|------------|----------|---------------------|\n| order_id   | INT      | Primary key.        |\n| customer_id| INT      | Customer ID.        |\n| order_date | DATE     | Date of the order.  |\n| amount     | DECIMAL  | Order amount.       |",
    "correctQuery": "SELECT order_id, customer_id, order_date FROM orders WHERE order_date BETWEEN '2025-01-01' AND '2025-01-31' ORDER BY order_date;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, customer_id INT, order_date DATE, amount DECIMAL(10,2));\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (1, 101, '2024-12-30', 50.00);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (2, 102, '2025-01-15', 120.00);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (3, 103, '2025-01-31', 99.99);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (4, 104, '2025-02-01', 150.00);",
    "hints": ["Use the BETWEEN operator for the date range."]
  },
  {
    "id": 35,
    "title": "Uppercase Country Codes",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given a `users` table. For each user, return their `user_id`, `name`, and `country` converted to **uppercase**.\nReturn results sorted by `user_id`.\n\n### Table: `users`\n\n| Column   | Type    | Description         |\n|---------|---------|---------------------|\n| user_id | INT     | Primary key.        |\n| name    | VARCHAR | User name.          |\n| country | VARCHAR | ISO country code.   |",
    "correctQuery": "SELECT user_id, name, UPPER(country) AS country FROM users ORDER BY user_id;",
    "sourceTableQuery": "CREATE TABLE users (user_id INT PRIMARY KEY, name VARCHAR(255), country VARCHAR(5));\nINSERT INTO users (user_id, name, country) VALUES (1, 'Alice', 'us');\nINSERT INTO users (user_id, name, country) VALUES (2, 'Bob', 'ca');\nINSERT INTO users (user_id, name, country) VALUES (3, 'Carol', 'uk');",
    "hints": ["Use the UPPER() string function."]
  },
  {
    "id": 36,
    "title": "Email Domain Extraction",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given a `subscribers` table with email addresses.\nExtract the **domain** (the part after `@`) for each email.\nReturn `subscriber_id` and `domain`, sorted by `subscriber_id`.\n\n### Table: `subscribers`\n\n| Column        | Type    | Description          |\n|--------------|---------|----------------------|\n| subscriber_id| INT     | Primary key.         |\n| email        | VARCHAR | Subscriber's email.  |",
    "correctQuery": "SELECT subscriber_id, SUBSTR(email, INSTR(email, '@') + 1) AS domain FROM subscribers ORDER BY subscriber_id;",
    "sourceTableQuery": "CREATE TABLE subscribers (subscriber_id INT PRIMARY KEY, email VARCHAR(255));\nINSERT INTO subscribers (subscriber_id, email) VALUES (1, 'alice@company.com');\nINSERT INTO subscribers (subscriber_id, email) VALUES (2, 'bob.s@gmail.com');\nINSERT INTO subscribers (subscriber_id, email) VALUES (3, 'carol@co.uk');",
    "hints": ["Use INSTR() to find the position of '@' and SUBSTR() to slice the string."]
  },
  {
    "id": 37,
    "title": "Total Spend per Customer",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given an `orders` table. For each customer, compute the **total amount** they have spent.\nReturn `customer_id` and `total_spent`, sorted by `total_spent` descending.\n\n### Table: `orders`\n\n| Column      | Type     | Description         |\n|------------|----------|---------------------|\n| order_id   | INT      | Primary key.        |\n| customer_id| INT      | Customer ID.        |\n| order_date | DATE     | Date of the order.  |\n| amount     | DECIMAL  | Order amount.       |",
    "correctQuery": "SELECT customer_id, SUM(amount) AS total_spent FROM orders GROUP BY customer_id ORDER BY total_spent DESC;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, customer_id INT, order_date DATE, amount DECIMAL(10,2));\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (1, 101, '2025-01-01', 50.00);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (2, 102, '2025-01-05', 120.00);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (3, 101, '2025-01-08', 99.99);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (4, 103, '2025-01-10', 10.00);",
    "hints": ["Group the results by customer_id and sum the amount."]
  },
  {
    "id": 38,
    "title": "Inactive Users",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given a `users` table. Return all users whose `status` is **not** `'active'`.\nReturn `user_id`, `name`, and `status`, sorted by `user_id`.\n\n### Table: `users`\n\n| Column   | Type    | Description                        |\n|---------|---------|------------------------------------|\n| user_id | INT     | Primary key.                       |\n| name    | VARCHAR | Name of the user.                  |\n| status  | VARCHAR | `'active'`, `'inactive'`, etc.     |",
    "correctQuery": "SELECT user_id, name, status FROM users WHERE status != 'active' ORDER BY user_id;",
    "sourceTableQuery": "CREATE TABLE users (user_id INT PRIMARY KEY, name VARCHAR(255), status VARCHAR(20));\nINSERT INTO users (user_id, name, status) VALUES (1, 'Alice', 'active');\nINSERT INTO users (user_id, name, status) VALUES (2, 'Bob', 'inactive');\nINSERT INTO users (user_id, name, status) VALUES (3, 'Carol', 'pending');",
    "hints": ["Filter using the != (not equal) operator in the WHERE clause."]
  },
  {
    "id": 39,
    "title": "Latest Login per User",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given a `logins` table. For each user, find their **most recent** login timestamp.\nReturn `user_id` and `last_login`, sorted by `user_id`.\n\n### Table: `logins`\n\n| Column     | Type      | Description             |\n|-----------|-----------|-------------------------|\n| user_id   | INT       | User ID.                |\n| login_time| TIMESTAMP | Time of the login.      |",
    "correctQuery": "SELECT user_id, MAX(login_time) AS last_login FROM logins GROUP BY user_id ORDER BY user_id;",
    "sourceTableQuery": "CREATE TABLE logins (user_id INT, login_time TIMESTAMP);\nINSERT INTO logins (user_id, login_time) VALUES (1, '2025-01-01 10:00:00');\nINSERT INTO logins (user_id, login_time) VALUES (1, '2025-01-01 11:30:00');\nINSERT INTO logins (user_id, login_time) VALUES (2, '2025-01-01 09:00:00');\nINSERT INTO logins (user_id, login_time) VALUES (2, '2024-12-31 15:00:00');",
    "hints": ["Group by user_id and select the MAX(login_time)."]
  },
  {
    "id": 40,
    "title": "Count Distinct Products per Order",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given an `order_items` table. For each order, count how many **distinct products** were included.\nReturn `order_id` and `product_count`, sorted by `order_id`.\n\n### Table: `order_items`\n\n| Column      | Type | Description                          |\n|------------|------|------------------------------------|\n| order_id   | INT  | Order identifier.                   |\n| product_id | INT  | Product identifier.                 |\n| quantity   | INT  | Quantity of this product in order. |",
    "correctQuery": "SELECT order_id, COUNT(DISTINCT product_id) AS product_count FROM order_items GROUP BY order_id ORDER BY order_id;",
    "sourceTableQuery": "CREATE TABLE order_items (order_id INT, product_id INT, quantity INT);\nINSERT INTO order_items (order_id, product_id, quantity) VALUES (101, 1, 1);\nINSERT INTO order_items (order_id, product_id, quantity) VALUES (101, 2, 1);\nINSERT INTO order_items (order_id, product_id, quantity) VALUES (101, 1, 1); -- Duplicate product ID in same order\nINSERT INTO order_items (order_id, product_id, quantity) VALUES (102, 3, 5);",
    "hints": ["Use COUNT(DISTINCT column_name) to avoid counting duplicates."]
  },
  {
    "id": 41,
    "title": "Average Rating per Product",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given a `reviews` table. For each product, compute the **average rating** to two decimal places.\nReturn `product_id` and `avg_rating`, sorted by `product_id`.\n\n### Table: `reviews`\n\n| Column     | Type   | Description        |\n|-----------|--------|--------------------|\n| review_id | INT    | Primary key.       |\n| product_id| INT    | Product reviewed.  |\n| rating    | INT    | Rating from 1 to 5 |",
    "correctQuery": "SELECT product_id, ROUND(AVG(rating), 2) AS avg_rating FROM reviews GROUP BY product_id ORDER BY product_id;",
    "sourceTableQuery": "CREATE TABLE reviews (review_id INT PRIMARY KEY, product_id INT, rating INT);\nINSERT INTO reviews (review_id, product_id, rating) VALUES (1, 10, 4);\nINSERT INTO reviews (review_id, product_id, rating) VALUES (2, 10, 5);\nINSERT INTO reviews (review_id, product_id, rating) VALUES (3, 20, 3);\nINSERT INTO reviews (review_id, product_id, rating) VALUES (4, 20, 5);\nINSERT INTO reviews (review_id, product_id, rating) VALUES (5, 20, 1);",
    "hints": ["Aggregate by product_id and use ROUND(AVG(rating), 2)."]
  },
  {
    "id": 42,
    "title": "Employees Hired After 2020",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given an `employees` table. Return all employees who were hired **after** 2020-12-31.\nReturn `emp_id`, `name`, and `hire_date`, sorted by `hire_date`.\n\n### Table: `employees`\n\n| Column   | Type   | Description         |\n|---------|--------|---------------------|\n| emp_id  | INT    | Primary key.        |\n| name    | VARCHAR| Employee name.      |\n| hire_date| DATE  | Hire date.          |",
    "correctQuery": "SELECT emp_id, name, hire_date FROM employees WHERE hire_date > '2020-12-31' ORDER BY hire_date;",
    "sourceTableQuery": "CREATE TABLE employees (emp_id INT PRIMARY KEY, name VARCHAR(255), hire_date DATE);\nINSERT INTO employees (emp_id, name, hire_date) VALUES (1, 'Alice', '2020-11-01');\nINSERT INTO employees (emp_id, name, hire_date) VALUES (2, 'Bob', '2021-01-01');\nINSERT INTO employees (emp_id, name, hire_date) VALUES (3, 'Carol', '2021-06-30');",
    "hints": ["Standard comparisons (>, <) work on date strings in 'YYYY-MM-DD' format."]
  },
  {
    "id": 43,
    "title": "Top 5 Most Expensive Products",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given a `products` table. Return the **top 5** products with the highest `price`.\nIf there are ties, break them by `product_id` ascending.\n\n### Table: `products`\n\n| Column     | Type    | Description      |\n|-----------|---------|------------------|\n| product_id| INT     | Primary key.     |\n| name      | VARCHAR | Product name.    |\n| price     | DECIMAL | Product price.   |\n\n### Requirements\n\nReturn the **top 5** products with the highest `price`.\nIf there are ties, break them by `product_id` ascending.",
    "correctQuery": "SELECT product_id, name, price FROM products ORDER BY price DESC, product_id ASC LIMIT 5;",
    "sourceTableQuery": "CREATE TABLE products (product_id INT PRIMARY KEY, name VARCHAR(255), price DECIMAL(10,2));\nINSERT INTO products (product_id, name, price) VALUES (1, 'A', 1000.00);\nINSERT INTO products (product_id, name, price) VALUES (2, 'B', 950.00);\nINSERT INTO products (product_id, name, price) VALUES (3, 'C', 1000.00);\nINSERT INTO products (product_id, name, price) VALUES (4, 'D', 800.00);\nINSERT INTO products (product_id, name, price) VALUES (5, 'E', 750.00);\nINSERT INTO products (product_id, name, price) VALUES (6, 'F', 750.00);",
    "hints": ["Sort the results by price descending and then limit the output."]
  },
  {
    "id": 44,
    "title": "Users Without Email",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given a `users` table. Find all users whose `email` is `NULL` or an empty string.\nReturn `user_id` and `name`, sorted by `user_id`.\n\n### Table: `users`\n\n| Column   | Type    | Description         |\n|---------|---------|---------------------|\n| user_id | INT     | Primary key.        |\n| name    | VARCHAR | User name.          |\n| email   | VARCHAR | Email address.      |",
    "correctQuery": "SELECT user_id, name FROM users WHERE email IS NULL OR email = '' ORDER BY user_id;",
    "sourceTableQuery": "CREATE TABLE users (user_id INT PRIMARY KEY, name VARCHAR(255), email VARCHAR(255));\nINSERT INTO users (user_id, name, email) VALUES (1, 'Alice', 'alice@example.com');\nINSERT INTO users (user_id, name, email) VALUES (2, 'Bob', NULL);\nINSERT INTO users (user_id, name, email) VALUES (3, 'Carol', '');\nINSERT INTO users (user_id, name, email) VALUES (4, 'David', 'david@test.com');",
    "hints": ["Use IS NULL to check for NULL values, and compare against '' for empty strings."]
  },
  {
    "id": 45,
    "title": "Count Orders per Status",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given an `orders` table. Count how many orders have each `status`.\nReturn `status` and `order_count`, sorted by `order_count` descending.\n\n### Table: `orders`\n\n| Column      | Type    | Description              |\n|-----------|---------|--------------------------|\n| order_id  | INT     | Primary key.             |\n| status    | VARCHAR | 'pending','paid', etc.   |\n| order_date| DATE    | Date the order was made. |",
    "correctQuery": "SELECT status, COUNT(order_id) AS order_count FROM orders GROUP BY status ORDER BY order_count DESC;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, status VARCHAR(50), order_date DATE);\nINSERT INTO orders (order_id, status, order_date) VALUES (1, 'paid', '2025-01-01');\nINSERT INTO orders (order_id, status, order_date) VALUES (2, 'pending', '2025-01-02');\nINSERT INTO orders (order_id, status, order_date) VALUES (3, 'paid', '2025-01-03');\nINSERT INTO orders (order_id, status, order_date) VALUES (4, 'shipped', '2025-01-04');\nINSERT INTO orders (order_id, status, order_date) VALUES (5, 'paid', '2025-01-05');",
    "hints": ["Use GROUP BY status and count the primary keys."]
  },
  {
    "id": 46,
    "title": "Combine First and Last Name",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given a `people` table. For each row, return a single `full_name` column in the format `'first_name last_name'`.\nReturn `person_id` and `full_name`, sorted by `person_id`.\n\n### Table: `people`\n\n| Column     | Type    | Description         |\n|-----------|---------|---------------------|\n| person_id | INT     | Primary key.        |\n| first_name| VARCHAR | First name.         |\n| last_name | VARCHAR | Last name.          |",
    "correctQuery": "SELECT person_id, first_name || ' ' || last_name AS full_name FROM people ORDER BY person_id;",
    "sourceTableQuery": "CREATE TABLE people (person_id INT PRIMARY KEY, first_name VARCHAR(255), last_name VARCHAR(255));\nINSERT INTO people (person_id, first_name, last_name) VALUES (1, 'John', 'Doe');\nINSERT INTO people (person_id, first_name, last_name) VALUES (2, 'Jane', 'Smith');\nINSERT INTO people (person_id, first_name, last_name) VALUES (3, 'Bob', 'Jones');",
    "hints": ["In SQLite, use the || operator to concatenate strings."]
  },
  {
    "id": 47,
    "title": "Find Duplicate Emails",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given a `users` table. Find all email addresses that appear **more than once**.\nReturn `email` and `user_count`.\n\n### Table: `users`\n\n| Column   | Type    | Description         |\n|---------|---------|---------------------|\n| user_id | INT     | Primary key.        |\n| email   | VARCHAR | Email address.      |",
    "correctQuery": "SELECT email, COUNT(user_id) AS user_count FROM users GROUP BY email HAVING COUNT(user_id) > 1;",
    "sourceTableQuery": "CREATE TABLE users (user_id INT PRIMARY KEY, email VARCHAR(255));\nINSERT INTO users (user_id, email) VALUES (1, 'a@test.com');\nINSERT INTO users (user_id, email) VALUES (2, 'b@test.com');\nINSERT INTO users (user_id, email) VALUES (3, 'a@test.com');\nINSERT INTO users (user_id, email) VALUES (4, 'c@test.com');",
    "hints": ["Group by email and use the HAVING clause to filter groups with count > 1."]
  },
  {
    "id": 48,
    "title": "Earliest Order per Customer",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given an `orders` table. For each customer, find the date of their **first order**.\nReturn `customer_id` and `first_order_date`, sorted by `customer_id`.\n\n### Table: `orders`\n\n| Column      | Type     | Description         |\n|------------|----------|---------------------|\n| order_id   | INT      | Primary key.        |\n| customer_id| INT      | Customer ID.        |\n| order_date | DATE     | Date of the order.  |\n| amount     | DECIMAL  | Order amount.       |",
    "correctQuery": "SELECT customer_id, MIN(order_date) AS first_order_date FROM orders GROUP BY customer_id ORDER BY customer_id;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, customer_id INT, order_date DATE, amount DECIMAL(10,2));\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (1, 101, '2025-01-10', 50.00);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (2, 101, '2025-01-01', 120.00);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (3, 102, '2025-01-05', 99.99);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (4, 102, '2025-01-20', 150.00);",
    "hints": ["Group by customer_id and use the MIN() function on the date."]
  },
  {
    "id": 49,
    "title": "Customers with Exactly One Order",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given an `orders` table. Find customers who have placed **exactly one** order.\nReturn `customer_id`, sorted ascending.\n\n### Table: `orders`\n\n| Column      | Type     | Description         |\n|------------|----------|---------------------|\n| order_id   | INT      | Primary key.        |\n| customer_id| INT      | Customer ID.        |\n| order_date | DATE     | Date of the order.  |",
    "correctQuery": "SELECT customer_id FROM orders GROUP BY customer_id HAVING COUNT(order_id) = 1 ORDER BY customer_id ASC;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, customer_id INT, order_date DATE);\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (1, 101, '2025-01-01');\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (2, 102, '2025-01-05');\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (3, 102, '2025-01-08');\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (4, 103, '2025-01-10');",
    "hints": ["Group by customer_id and use HAVING count = 1."]
  },
  {
    "id": 50,
    "title": "Average Session Duration",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given a `sessions` table. Each row has a start and end timestamp for a user session.\nCompute the **average session duration in minutes**, rounded to 2 decimals.\nReturn a single row with `avg_minutes`.\n\n### Table: `sessions`\n\n| Column     | Type      | Description                 |\n|-----------|-----------|-----------------------------|\n| session_id| INT       | Primary key.                |\n| user_id   | INT       | User ID.                    |\n| start_time| TIMESTAMP | Session start time.         |\n| end_time  | TIMESTAMP | Session end time.           |\n",
    "correctQuery": "SELECT ROUND(AVG((julianday(end_time) - julianday(start_time)) * 24 * 60), 2) AS avg_minutes FROM sessions;",
    "sourceTableQuery": "CREATE TABLE sessions (session_id INT PRIMARY KEY, user_id INT, start_time TIMESTAMP, end_time TIMESTAMP);\nINSERT INTO sessions (session_id, user_id, start_time, end_time) VALUES (1, 10, '2025-01-01 10:00:00', '2025-01-01 10:30:00');\nINSERT INTO sessions (session_id, user_id, start_time, end_time) VALUES (2, 20, '2025-01-01 11:00:00', '2025-01-01 11:15:00');\nINSERT INTO sessions (session_id, user_id, start_time, end_time) VALUES (3, 10, '2025-01-01 12:00:00', '2025-01-01 12:45:00');",
    "hints": ["In SQLite, use julianday() to subtract timestamps, which returns result in days. Multiply by 24*60 to get minutes."]
  },
  {
    "id": 51,
    "title": "Monthly Active Customers",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given an `orders` table. A customer is **active** in a month if they placed at least one order in that month.\nFor each month, count distinct active customers.\nReturn `month` (YYYY-MM) and `active_customers`, sorted by `month`.\n\n### Table: `orders`\n\n| Column      | Type     | Description         |\n|------------|----------|---------------------|\n| order_id   | INT      | Primary key.        |\n| customer_id| INT      | Customer ID.        |\n| order_date | DATE     | Date of the order.  |",
    "correctQuery": "SELECT strftime('%Y-%m', order_date) AS month, COUNT(DISTINCT customer_id) AS active_customers FROM orders GROUP BY 1 ORDER BY 1;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, customer_id INT, order_date DATE);\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (1, 10, '2025-01-05');\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (2, 20, '2025-01-10');\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (3, 10, '2025-02-01');\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (4, 30, '2025-02-15');",
    "hints": ["Format the date to YYYY-MM using strftime and count distinct customer IDs."]
  },
  {
    "id": 52,
    "title": "RFM Scoring: Recency and Frequency",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given an `orders` table.\nFor each customer, compute:\n- `last_order_date`\n- `order_count`\nUse window functions to compute each metric.\nReturn `customer_id`, `last_order_date`, and `order_count`.\n\n### Table: `orders`\n\n| Column      | Type     | Description         |\n|------------|----------|---------------------|\n| order_id   | INT      | Primary key.        |\n| customer_id| INT      | Customer ID.        |\n| order_date | DATE     | Date of the order.  |",
    "correctQuery": "WITH CustomerStats AS (SELECT customer_id, MAX(order_date) AS last_order_date, COUNT(order_id) AS order_count FROM orders GROUP BY customer_id) SELECT customer_id, last_order_date, order_count FROM CustomerStats ORDER BY customer_id;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, customer_id INT, order_date DATE);\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (1, 10, '2025-01-01');\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (2, 20, '2025-01-05');\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (3, 10, '2025-01-10');\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (4, 20, '2025-01-15');\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (5, 30, '2025-01-20');",
    "hints": ["This can be done with simple aggregation (MAX and COUNT) grouped by customer."]
  },
  {
    "id": 53,
    "title": "Users with Consecutive Missed Days",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given a `logins` table. Find users who have at least **3 consecutive days without logging in** between two of their logins.\nReturn `user_id`.\n\n### Table: `logins`\n\n| Column     | Type | Description        |\n|-----------|------|--------------------|\n| user_id   | INT  | User ID.           |\n| login_date| DATE | Date they logged in|",
    "correctQuery": "WITH LaggedLogins AS (SELECT user_id, login_date, LAG(login_date, 1, NULL) OVER (PARTITION BY user_id ORDER BY login_date) AS prev_login_date FROM logins) SELECT DISTINCT user_id FROM LaggedLogins WHERE julianday(login_date) - julianday(prev_login_date) >= 4 ORDER BY user_id;",
    "sourceTableQuery": "CREATE TABLE logins (user_id INT, login_date DATE);\nINSERT INTO logins (user_id, login_date) VALUES (10, '2025-01-01');\nINSERT INTO logins (user_id, login_date) VALUES (10, '2025-01-02');\nINSERT INTO logins (user_id, login_date) VALUES (10, '2025-01-06'); -- 3 missed days (3, 4, 5)\nINSERT INTO logins (user_id, login_date) VALUES (20, '2025-01-01');\nINSERT INTO logins (user_id, login_date) VALUES (20, '2025-01-03'); -- 1 missed day",
    "hints": ["Use LAG() to get the previous login date.", "If the difference between current and previous date is >= 4, it means 3 days were skipped."]
  },
  {
    "id": 54,
    "title": "Rolling 7-Day Revenue",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given a `daily_revenue` table with one row per date.\nCompute the **7-day rolling sum** of revenue ending at each date.\nReturn `rev_date` and `revenue_7d`, sorted by `rev_date`.\n\n### Table: `daily_revenue`\n\n| Column   | Type   | Description      |\n|---------|--------|------------------|\n| rev_date| DATE   | Revenue date.    |\n| amount  | DECIMAL| Revenue amount.  |",
    "correctQuery": "SELECT rev_date, SUM(amount) OVER (ORDER BY rev_date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS revenue_7d FROM daily_revenue ORDER BY rev_date;",
    "sourceTableQuery": "CREATE TABLE daily_revenue (rev_date DATE, amount DECIMAL(10,2));\nINSERT INTO daily_revenue (rev_date, amount) VALUES ('2025-01-01', 10.00);\nINSERT INTO daily_revenue (rev_date, amount) VALUES ('2025-01-02', 20.00);\nINSERT INTO daily_revenue (rev_date, amount) VALUES ('2025-01-03', 15.00);\nINSERT INTO daily_revenue (rev_date, amount) VALUES ('2025-01-04', 5.00);\nINSERT INTO daily_revenue (rev_date, amount) VALUES ('2025-01-05', 30.00);\nINSERT INTO daily_revenue (rev_date, amount) VALUES ('2025-01-06', 10.00);\nINSERT INTO daily_revenue (rev_date, amount) VALUES ('2025-01-07', 20.00);\nINSERT INTO daily_revenue (rev_date, amount) VALUES ('2025-01-08', 25.00);",
    "hints": ["Use a window function with ROWS BETWEEN 6 PRECEDING AND CURRENT ROW."]
  },
  {
    "id": 55,
    "title": "Top 3 Customers per Country",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given `customers` and `orders` tables.\nCompute total spend per customer, then for each country return the **top 3 customers** by spend.\nReturn `country`, `customer_id`, and `total_spent`.\n\n### Table: `customers`\n\n| Column      | Type   | Description   |\n|------------|--------|---------------|\n| customer_id| INT    | Primary key.  |\n| name       | VARCHAR| Customer name.|\n| country    | VARCHAR| Country code. |\n\n### Table: `orders`\n\n| Column      | Type   | Description         |\n|------------|--------|---------------------|\n| order_id   | INT    | Primary key.        |\n| customer_id| INT    | Customer ID.        |\n| amount     | DECIMAL| Order amount.       |",
    "correctQuery": "WITH CustomerSpend AS (SELECT c.customer_id, c.country, SUM(o.amount) AS total_spent FROM customers c JOIN orders o ON c.customer_id = o.customer_id GROUP BY 1, 2), RankedCustomers AS (SELECT *, DENSE_RANK() OVER (PARTITION BY country ORDER BY total_spent DESC) AS spend_rank FROM CustomerSpend) SELECT country, customer_id, total_spent FROM RankedCustomers WHERE spend_rank <= 3 ORDER BY country, total_spent DESC;",
    "sourceTableQuery": "CREATE TABLE customers (customer_id INT PRIMARY KEY, name VARCHAR(255), country VARCHAR(3));\nINSERT INTO customers (customer_id, name, country) VALUES (1, 'Alice', 'US');\nINSERT INTO customers (customer_id, name, country) VALUES (2, 'Bob', 'US');\nINSERT INTO customers (customer_id, name, country) VALUES (3, 'Carol', 'CA');\nINSERT INTO customers (customer_id, name, country) VALUES (4, 'David', 'US');\nCREATE TABLE orders (order_id INT PRIMARY KEY, customer_id INT, amount DECIMAL(10,2));\nINSERT INTO orders (order_id, customer_id, amount) VALUES (101, 1, 100.00);\nINSERT INTO orders (order_id, customer_id, amount) VALUES (102, 2, 200.00);\nINSERT INTO orders (order_id, customer_id, amount) VALUES (103, 3, 50.00);\nINSERT INTO orders (order_id, customer_id, amount) VALUES (104, 1, 50.00);\nINSERT INTO orders (order_id, customer_id, amount) VALUES (105, 4, 300.00);",
    "hints": ["First calculate total spend per customer.", "Then use DENSE_RANK() partitioned by country to rank them."]
  },
  {
    "id": 56,
    "title": "Product Conversion Funnel",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given an `events` table representing a funnel with steps `'view'`, `'add_to_cart'`, `'purchase'`.\nFor each product, count how many users performed each step and compute conversion rates between steps.\nReturn `product_id`, `views`, `adds`, `purchases`, `view_to_add_rate`, and `add_to_purchase_rate`.\n\n### Table: `events`\n\n| Column      | Type    | Description                |\n|------------|---------|----------------------------|\n| user_id    | INT     | User performing the event. |\n| product_id | INT     | Product involved.          |\n| event_type | VARCHAR | 'view','add_to_cart','purchase' |\n| event_time | TIMESTAMP | Event timestamp.        |",
    "correctQuery": "WITH FunnelCounts AS (SELECT product_id, SUM(CASE WHEN event_type = 'view' THEN 1 ELSE 0 END) AS views, SUM(CASE WHEN event_type = 'add_to_cart' THEN 1 ELSE 0 END) AS adds, SUM(CASE WHEN event_type = 'purchase' THEN 1 ELSE 0 END) AS purchases FROM events GROUP BY product_id) SELECT product_id, views, adds, purchases, ROUND(CAST(adds AS REAL) / views, 2) AS view_to_add_rate, ROUND(CAST(purchases AS REAL) / adds, 2) AS add_to_purchase_rate FROM FunnelCounts;",
    "sourceTableQuery": "CREATE TABLE events (user_id INT, product_id INT, event_type VARCHAR(50), event_time TIMESTAMP);\nINSERT INTO events (user_id, product_id, event_type, event_time) VALUES (1, 10, 'view', '2025-01-01 10:00:00');\nINSERT INTO events (user_id, product_id, event_type, event_time) VALUES (1, 10, 'add_to_cart', '2025-01-01 10:05:00');\nINSERT INTO events (user_id, product_id, event_type, event_time) VALUES (1, 10, 'purchase', '2025-01-01 10:10:00');\nINSERT INTO events (user_id, product_id, event_type, event_time) VALUES (2, 20, 'view', '2025-01-01 11:00:00');\nINSERT INTO events (user_id, product_id, event_type, event_time) VALUES (2, 20, 'add_to_cart', '2025-01-01 11:05:00');",
    "hints": ["Use conditional aggregation (SUM(CASE...)) to count each event type per product."]
  },
  {
    "id": 57,
    "title": "Sessionize Clickstream Events",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given a `clicks` table where each row is a page view.\nDefine a **session** as a sequence of events by the same user where adjacent events are at most 30 minutes apart.\nAssign a `session_id` per user and event using window functions.\nReturn `user_id`, `event_time`, and `session_id`.\n\n### Table: `clicks`\n\n| Column    | Type      | Description      |\n|----------|-----------|------------------|\n| user_id  | INT       | User ID.         |\n| event_time| TIMESTAMP| Time of the click|",
    "correctQuery": "WITH LaggedTime AS (SELECT user_id, event_time, julianday(event_time) AS current_jday, julianday(LAG(event_time) OVER (PARTITION BY user_id ORDER BY event_time)) AS prev_jday FROM clicks), SessionStarts AS (SELECT user_id, event_time, CASE WHEN (current_jday - prev_jday) * 24 * 60 > 30 OR prev_jday IS NULL THEN 1 ELSE 0 END AS is_new_session FROM LaggedTime), SessionGroups AS (SELECT user_id, event_time, SUM(is_new_session) OVER (PARTITION BY user_id ORDER BY event_time) AS session_group FROM SessionStarts) SELECT user_id, event_time, (user_id * 100000 + session_group) AS session_id FROM SessionGroups ORDER BY user_id, event_time;",
    "sourceTableQuery": "CREATE TABLE clicks (user_id INT, event_time TIMESTAMP);\nINSERT INTO clicks (user_id, event_time) VALUES (1, '2025-01-01 10:00:00');\nINSERT INTO clicks (user_id, event_time) VALUES (1, '2025-01-01 10:20:00'); -- Same session\nINSERT INTO clicks (user_id, event_time) VALUES (1, '2025-01-01 11:00:00'); -- New session (40 min gap)\nINSERT INTO clicks (user_id, event_time) VALUES (2, '2025-01-01 10:00:00');",
    "hints": ["Calculate the time difference between the current row and the previous row.", "If diff > 30 mins, mark it as the start of a new session (1), else 0. Then compute a running sum."]
  },
  {
    "id": 58,
    "title": "Median Order Value per Month",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given an `orders` table. For each month (YYYY-MM), compute the **median order amount**.\nReturn `month` and `median_amount`, sorted by `month`.\n\n### Table: `orders`\n\n| Column      | Type     | Description         |\n|------------|---------|---------------------|\n| order_id   | INT      | Primary key.        |\n| order_date | DATE     | Date of the order.  |\n| amount     | DECIMAL | Order amount.       |\n\n### Requirements\n\nReturn `month` and `median_amount`, sorted by `month`.",
    "correctQuery": "WITH MonthlyOrders AS (SELECT strftime('%Y-%m', order_date) AS month, amount FROM orders), RankedOrders AS (SELECT month, amount, ROW_NUMBER() OVER (PARTITION BY month ORDER BY amount) AS rn, COUNT(*) OVER (PARTITION BY month) AS count_month FROM MonthlyOrders) SELECT month, AVG(amount) AS median_amount FROM RankedOrders WHERE rn IN ((count_month + 1) / 2, (count_month + 2) / 2) GROUP BY month ORDER BY month;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, order_date DATE, amount DECIMAL(10,2));\nINSERT INTO orders (order_id, order_date, amount) VALUES (1, '2025-01-01', 10.00);\nINSERT INTO orders (order_id, order_date, amount) VALUES (2, '2025-01-05', 30.00);\nINSERT INTO orders (order_id, order_date, amount) VALUES (3, '2025-01-10', 20.00);\nINSERT INTO orders (order_id, order_date, amount) VALUES (4, '2025-02-01', 50.00);",
    "hints": ["Rank the amounts within each month and pick the middle rank."]
  },
  {
    "id": 59,
    "title": "Customer Lifetime Value Snapshot",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given a `orders` table and a snapshot date parameter (e.g. `'2025-01-31'`).\nFor each customer, compute:\n- total revenue up to the snapshot date\n- first order date\nReturn `customer_id`, `first_order_date`, and `lifetime_revenue`.\n\n### Table: `orders`\n\n| Column      | Type     | Description         |\n|------------|---------|---------------------|\n| order_id   | INT      | Primary key.        |\n| customer_id| INT      | Customer ID.        |\n| order_date | DATE     | Date of the order.  |\n| amount     | DECIMAL | Order amount.       |",
    "correctQuery": "WITH FilteredOrders AS (SELECT customer_id, order_date, amount FROM orders WHERE order_date <= '2025-01-31') SELECT customer_id, MIN(order_date) AS first_order_date, SUM(amount) AS lifetime_revenue FROM FilteredOrders GROUP BY customer_id ORDER BY customer_id;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, customer_id INT, order_date DATE, amount DECIMAL(10,2));\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (1, 10, '2025-01-15', 100.00);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (2, 20, '2025-01-20', 50.00);\nINSERT INTO orders (order_id, customer_id, order_date, amount) VALUES (3, 10, '2025-02-01', 200.00); -- After snapshot",
    "hints": ["Filter orders by date first, then group by customer."]
  },
  {
    "id": 60,
    "title": "Identify Power Users",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given a `logins` table. A **power user** is defined as logging in on at least 20 different days within a 30-day window.\nFind all power users using window functions.\nReturn `user_id`.\n\n### Table: `logins`\n\n| Column     | Type | Description        |\n|-----------|------|--------------------|\n| user_id   | INT  | User ID.           |\n| login_date| DATE | Date of login.     |",
    "correctQuery": "WITH DistinctLogins AS (SELECT DISTINCT user_id, login_date FROM logins), DateWindow AS (SELECT user_id, login_date, COUNT(login_date) OVER (PARTITION BY user_id ORDER BY login_date RANGE BETWEEN 29 PRECEDING AND CURRENT ROW) AS distinct_days_30 FROM DistinctLogins) SELECT DISTINCT user_id FROM DateWindow WHERE distinct_days_30 >= 20 ORDER BY user_id;",
    "sourceTableQuery": "CREATE TABLE logins (user_id INT, login_date DATE);\nINSERT INTO logins (user_id, login_date) VALUES (1, '2025-01-01');\n-- ... simulate 20 logins in 30 days for user 1 ...\nINSERT INTO logins (user_id, login_date) VALUES (2, '2025-01-01');\n-- ... simulate 10 logins in 30 days for user 2 ...\nINSERT INTO logins (user_id, login_date) VALUES (1, '2025-01-30');",
    "hints": ["Use COUNT() OVER a sliding window of time (RANGE BETWEEN ...)."]
  },
  {
    "id": 61,
    "title": "Order Frequency Segments",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given an `orders` table.\nFor each customer, compute their order count and assign a segment:\n- `\"low\"` if count <= 2\n- `\"medium\"` if 3–5\n- `\"high\"` if > 5\nReturn `customer_id`, `order_count`, and `segment`.\n\n### Table: `orders`\n\n| Column      | Type   | Description         |\n|------------|--------|---------------------|\n| order_id   | INT    | Primary key.        |\n| customer_id| INT    | Customer ID.        |\n| order_date | DATE   | Date of order.      |",
    "correctQuery": "WITH CustomerCounts AS (SELECT customer_id, COUNT(order_id) AS order_count FROM orders GROUP BY customer_id) SELECT customer_id, order_count, CASE WHEN order_count <= 2 THEN 'low' WHEN order_count BETWEEN 3 AND 5 THEN 'medium' ELSE 'high' END AS segment FROM CustomerCounts ORDER BY customer_id;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, customer_id INT, order_date DATE);\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (1, 10, '2025-01-01');\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (2, 20, '2025-01-05');\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (3, 30, '2025-01-10');\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (4, 30, '2025-01-15');\nINSERT INTO orders (order_id, customer_id, order_date) VALUES (5, 30, '2025-01-20');",
    "hints": ["Use a CASE statement on the COUNT(order_id)."]
  },
  {
    "id": 62,
    "title": "AB Test Conversion Uplift",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given an `ab_events` table with experiment assignments and conversions.\nCompute conversion rates for variants 'A' and 'B' and the **uplift** B-A in percentage points.\nReturn `variant`, `users`, `conversions`, `conversion_rate`, and a second row summarizing uplift.\n\n### Table: `ab_events`\n\n| Column     | Type    | Description                          |\n|-----------|---------|-------------------------------------|\n| user_id   | INT     | User ID.                            |\n| variant   | VARCHAR | 'A' or 'B'.                         |\n| converted | INT     | 1 if converted in test period, 0 else|",
    "correctQuery": "WITH Rates AS (SELECT variant, COUNT(DISTINCT user_id) AS users, SUM(converted) AS conversions, CAST(SUM(converted) AS REAL) * 100 / COUNT(DISTINCT user_id) AS conversion_rate FROM ab_events GROUP BY variant), Uplift AS (SELECT 'Uplift B-A' AS variant, NULL AS users, NULL AS conversions, ROUND((SELECT conversion_rate FROM Rates WHERE variant = 'B') - (SELECT conversion_rate FROM Rates WHERE variant = 'A'), 2) AS conversion_rate) SELECT variant, users, conversions, ROUND(conversion_rate, 2) AS conversion_rate FROM Rates UNION ALL SELECT * FROM Uplift;",
    "sourceTableQuery": "CREATE TABLE ab_events (user_id INT, variant VARCHAR(10), converted INT);\nINSERT INTO ab_events (user_id, variant, converted) VALUES (1, 'A', 0);\nINSERT INTO ab_events (user_id, variant, converted) VALUES (2, 'A', 1);\nINSERT INTO ab_events (user_id, variant, converted) VALUES (3, 'A', 0);\nINSERT INTO ab_events (user_id, variant, converted) VALUES (4, 'B', 1);\nINSERT INTO ab_events (user_id, variant, converted) VALUES (5, 'B', 1);",
    "hints": ["Calculate rates for A and B separately, then use UNION ALL to append the difference row."]
  },
  {
    "id": 63,
    "title": "Time to First Purchase",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given `signups` and `orders` tables.\nFor each user who eventually purchases, compute the number of days between `signup_date` and their **first order**.\nReturn `user_id` and `days_to_first_purchase`.\n\n### Table: `signups`\n\n| Column    | Type   | Description      |\n|----------|--------|------------------|\n| user_id  | INT    | Primary key.     |\n| signup_date| DATE | Signup date.     |\n\n### Table: `orders`\n\n| Column      | Type   | Description         |\n|------------|--------|---------------------|\n| order_id   | INT    | Primary key.        |\n| user_id    | INT    | User ID.            |\n| order_date | DATE   | Date of the order.  |",
    "correctQuery": "WITH FirstOrder AS (SELECT user_id, MIN(order_date) AS first_order_date FROM orders GROUP BY user_id) SELECT s.user_id, julianday(fo.first_order_date) - julianday(s.signup_date) AS days_to_first_purchase FROM signups s JOIN FirstOrder fo ON s.user_id = fo.user_id ORDER BY s.user_id;",
    "sourceTableQuery": "CREATE TABLE signups (user_id INT PRIMARY KEY, signup_date DATE);\nINSERT INTO signups (user_id, signup_date) VALUES (1, '2025-01-01');\nINSERT INTO signups (user_id, signup_date) VALUES (2, '2025-01-05');\nINSERT INTO signups (user_id, signup_date) VALUES (3, '2025-01-10');\nCREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, order_date DATE);\nINSERT INTO orders (order_id, user_id, order_date) VALUES (101, 1, '2025-01-11');\nINSERT INTO orders (order_id, user_id, order_date) VALUES (102, 2, '2025-01-15');",
    "hints": ["Find the MIN(order_date) per user first, then join to signups and subtract."]
  },
  {
    "id": 64,
    "title": "Upsell Detection",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given `orders` and `order_items` tables.\nA customer is considered **upsold** on an order if they initially add exactly one product to the cart, but the final order contains more than one distinct product.\nAssume `cart_add_time` is not available; determine upsell using the first product added per order as the earliest `order_items` row by `created_at`.\nReturn `order_id` and `customer_id` for upsold orders.\n\n### Table: `order_items`\n\n| Column      | Type      | Description                        |\n|------------|-----------|------------------------------------|\n| order_id   | INT       | Order ID.                          |\n| product_id | INT       | Product ID.                        |\n| created_at | TIMESTAMP | Time item was added to the order.  |",
    "correctQuery": "WITH DistinctProducts AS (SELECT order_id, COUNT(DISTINCT product_id) AS distinct_count FROM order_items GROUP BY order_id) SELECT o.order_id, o.customer_id FROM orders o JOIN DistinctProducts dp ON o.order_id = dp.order_id WHERE dp.distinct_count > 1;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, customer_id INT);\nINSERT INTO orders (order_id, customer_id) VALUES (1, 10);\nINSERT INTO orders (order_id, customer_id) VALUES (2, 20);\nCREATE TABLE order_items (order_id INT, product_id INT, created_at TIMESTAMP);\nINSERT INTO order_items (order_id, product_id, created_at) VALUES (1, 100, '2025-01-01 10:00:00');\nINSERT INTO order_items (order_id, product_id, created_at) VALUES (1, 200, '2025-01-01 10:05:00'); -- Upsell\nINSERT INTO order_items (order_id, product_id, created_at) VALUES (2, 300, '2025-01-01 11:00:00');",
    "hints": ["Count the distinct product_id per order_id."]
  },
  {
    "id": 65,
    "title": "Top Referring Domains",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given a `pageviews` table with referrer URLs.\nExtract the **domain** from `referrer_url` and compute how many sessions started from each domain.\nAssume a new session starts when `is_session_start = 1`.\nReturn `domain` and `session_count`, sorted by `session_count` descending.\n\n### Table: `pageviews`\n\n| Column          | Type      | Description                      |\n|----------------|-----------|----------------------------------|\n| user_id        | INT       | User ID.                         |\n| event_time     | TIMESTAMP | Time of the page view.           |\n| is_session_start| INT      | 1 if this is the first pageview of a session. |\n| referrer_url   | VARCHAR   | Full referrer URL.               |",
    "correctQuery": "WITH SessionStarts AS (SELECT referrer_url FROM pageviews WHERE is_session_start = 1 AND referrer_url IS NOT NULL AND referrer_url != ''), Domains AS (SELECT SUBSTR(referrer_url, INSTR(referrer_url, '//') + 2, INSTR(SUBSTR(referrer_url, INSTR(referrer_url, '//') + 2), '/') - 1) AS domain FROM SessionStarts) SELECT domain, COUNT(*) AS session_count FROM Domains GROUP BY domain ORDER BY session_count DESC;",
    "sourceTableQuery": "CREATE TABLE pageviews (user_id INT, event_time TIMESTAMP, is_session_start INT, referrer_url VARCHAR(255));\nINSERT INTO pageviews (user_id, event_time, is_session_start, referrer_url) VALUES (1, '2025-01-01 10:00:00', 1, 'https://google.com/search');\nINSERT INTO pageviews (user_id, event_time, is_session_start, referrer_url) VALUES (2, '2025-01-01 10:05:00', 1, 'https://facebook.com/ad');\nINSERT INTO pageviews (user_id, event_time, is_session_start, referrer_url) VALUES (3, '2025-01-01 10:10:00', 1, 'https://google.com/images');\nINSERT INTO pageviews (user_id, event_time, is_session_start, referrer_url) VALUES (1, '2025-01-01 10:15:00', 0, NULL);",
    "hints": ["Filter for session starts first, then parse the URL string to extract the domain."]
  },
  {
    "id": 66,
    "title": "Chained Subscriptions",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given a `subscriptions` table where each row is a subscription period.\nFind users who have **no gaps** between consecutive subscriptions (the next `start_date` is the same as or before the previous `end_date` + 1 day).\nReturn `user_id` and total number of chained periods.\n\n### Table: `subscriptions`\n\n| Column       | Type | Description              |\n|-------------|------|--------------------------|\n| user_id     | INT  | User ID.                 |\n| start_date  | DATE | Subscription start date. |\n| end_date    | DATE | Subscription end date.   |",
    "correctQuery": "WITH LaggedDates AS (SELECT user_id, start_date, end_date, date(LAG(end_date) OVER (PARTITION BY user_id ORDER BY start_date), '+1 day') AS expected_start FROM subscriptions), ChainCheck AS (SELECT user_id, start_date, CASE WHEN expected_start IS NULL OR start_date <= expected_start THEN 0 ELSE 1 END AS is_gap FROM LaggedDates), GapGroup AS (SELECT user_id, start_date, SUM(is_gap) OVER (PARTITION BY user_id ORDER BY start_date) AS chain_group FROM ChainCheck) SELECT user_id, COUNT(*) AS total_chained_periods FROM GapGroup GROUP BY user_id HAVING COUNT(DISTINCT chain_group) = 1 ORDER BY user_id;",
    "sourceTableQuery": "CREATE TABLE subscriptions (user_id INT, start_date DATE, end_date DATE);\nINSERT INTO subscriptions (user_id, start_date, end_date) VALUES (1, '2025-01-01', '2025-01-31');\nINSERT INTO subscriptions (user_id, start_date, end_date) VALUES (1, '2025-02-01', '2025-02-28');\nINSERT INTO subscriptions (user_id, start_date, end_date) VALUES (2, '2025-01-01', '2025-01-15');\nINSERT INTO subscriptions (user_id, start_date, end_date) VALUES (2, '2025-01-20', '2025-01-30'); -- 4 day gap",
    "hints": ["Use LAG() to compare current start_date with previous end_date."]
  },
  {
    "id": 67,
    "title": "Product Seasonality Index",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given a `sales` table with units sold per product per date.\nFor each product and month (1–12), compute the **seasonality index** = (average units that month) / (overall average units across all months for that product).\nReturn `product_id`, `month`, and `seasonality_index`.\n\n### Table: `sales`\n\n| Column     | Type   | Description                |\n|-----------|--------|----------------------------|\n| product_id| INT    | Product ID.                |\n| sale_date | DATE   | Date of sale.              |\n| units     | INT    | Units sold on that date.   |",
    "correctQuery": "WITH MonthlyAvg AS (SELECT product_id, CAST(strftime('%m', sale_date) AS INTEGER) AS month, AVG(units) AS monthly_avg FROM sales GROUP BY 1, 2), OverallAvg AS (SELECT product_id, AVG(units) AS overall_avg FROM sales GROUP BY 1) SELECT ma.product_id, ma.month, ROUND(ma.monthly_avg / oa.overall_avg, 2) AS seasonality_index FROM MonthlyAvg ma JOIN OverallAvg oa ON ma.product_id = oa.product_id ORDER BY product_id, month;",
    "sourceTableQuery": "CREATE TABLE sales (product_id INT, sale_date DATE, units INT);\nINSERT INTO sales (product_id, sale_date, units) VALUES (1, '2025-01-01', 10);\nINSERT INTO sales (product_id, sale_date, units) VALUES (1, '2025-01-15', 10);\nINSERT INTO sales (product_id, sale_date, units) VALUES (1, '2025-02-01', 5);\nINSERT INTO sales (product_id, sale_date, units) VALUES (2, '2025-01-01', 50);",
    "hints": ["Compute the monthly averages and the global average separately, then join them."]
  },
  {
    "id": 68,
    "title": "Rank Products by Revenue Within Category",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given `products` and `order_items` tables.\nFor each category, compute total revenue per product and rank products by revenue using `DENSE_RANK()`.\nReturn `category`, `product_id`, `revenue`, and `revenue_rank`.\n\n### Table: `products`\n\n| Column     | Type    | Description    |\n|-----------|---------|----------------|\n| product_id| INT     | Primary key.   |\n| category  | VARCHAR | Category name. |\n\n### Table: `order_items`\n\n| Column      | Type    | Description                          |\n|------------|---------|--------------------------------------|\n| order_id   | INT     | Order ID.                            |\n| product_id | INT     | Product ID.                          |\n| quantity   | INT     | Quantity purchased.                  |\n| unit_price | DECIMAL | Price per unit at time of purchase.  |",
    "correctQuery": "WITH ProductRevenue AS (SELECT p.category, p.product_id, SUM(oi.quantity * oi.unit_price) AS revenue FROM products p JOIN order_items oi ON p.product_id = oi.product_id GROUP BY 1, 2) SELECT category, product_id, revenue, DENSE_RANK() OVER (PARTITION BY category ORDER BY revenue DESC) AS revenue_rank FROM ProductRevenue ORDER BY category, revenue DESC;",
    "sourceTableQuery": "CREATE TABLE products (product_id INT PRIMARY KEY, category VARCHAR(255));\nINSERT INTO products (product_id, category) VALUES (1, 'A');\nINSERT INTO products (product_id, category) VALUES (2, 'A');\nINSERT INTO products (product_id, category) VALUES (3, 'B');\nCREATE TABLE order_items (order_id INT, product_id INT, quantity INT, unit_price DECIMAL(10,2));\nINSERT INTO order_items (order_id, product_id, quantity, unit_price) VALUES (101, 1, 1, 100.00);\nINSERT INTO order_items (order_id, product_id, quantity, unit_price) VALUES (102, 1, 2, 100.00);\nINSERT INTO order_items (order_id, product_id, quantity, unit_price) VALUES (103, 2, 1, 300.00);\nINSERT INTO order_items (order_id, product_id, quantity, unit_price) VALUES (104, 3, 5, 50.00);",
    "hints": ["Calculate revenue per product first, then use DENSE_RANK() partitioned by category."]
  },
  {
    "id": 69,
    "title": "Repeat Purchase Rate",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given an `orders` table.\nCompute the **repeat purchase rate**: fraction of customers with more than one order.\nReturn a single row with `repeat_rate` as a decimal between 0 and 1.\n\n### Table: `orders`\n\n| Column      | Type   | Description         |\n|------------|--------|---------------------|\n| order_id   | INT    | Primary key.        |\n| customer_id| INT    | Customer ID.        |",
    "correctQuery": "WITH CustomerOrderCounts AS (SELECT customer_id, COUNT(order_id) AS order_count FROM orders GROUP BY customer_id) SELECT CAST(SUM(CASE WHEN order_count > 1 THEN 1 ELSE 0 END) AS REAL) / COUNT(customer_id) AS repeat_rate FROM CustomerOrderCounts;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, customer_id INT);\nINSERT INTO orders (order_id, customer_id) VALUES (1, 10);\nINSERT INTO orders (order_id, customer_id) VALUES (2, 20);\nINSERT INTO orders (order_id, customer_id) VALUES (3, 10);\nINSERT INTO orders (order_id, customer_id) VALUES (4, 30);",
    "hints": ["Count orders per customer, then divide the count of customers with >1 order by the total count."]
  },
  {
    "id": 70,
    "title": "Multi-Product Basket Analysis",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given an `order_items` table.\nFind all pairs of products `(product_a, product_b)` that appear together in at least 50 orders (ignoring order of the pair).\nReturn `product_a`, `product_b`, and `order_count`, sorted by `order_count` descending.\n\n### Table: `order_items`\n\n| Column      | Type | Description                          |\n|------------|------|------------------------------------|\n| order_id   | INT  | Order ID.                          |\n| product_id | INT  | Product ID.                        |",
    "correctQuery": "WITH ProductPairs AS (SELECT t1.product_id AS product_a, t2.product_id AS product_b, t1.order_id FROM order_items t1 JOIN order_items t2 ON t1.order_id = t2.order_id AND t1.product_id < t2.product_id) SELECT product_a, product_b, COUNT(order_id) AS order_count FROM ProductPairs GROUP BY product_a, product_b HAVING order_count >= 50 ORDER BY order_count DESC;",
    "sourceTableQuery": "CREATE TABLE order_items (order_id INT, product_id INT);\n-- Insert a large number of rows (at least 50 orders) where product 1 and 2 appear together\n-- Example (only showing 3 orders for brevity):\nINSERT INTO order_items (order_id, product_id) VALUES (1, 1);\nINSERT INTO order_items (order_id, product_id) VALUES (1, 2);\nINSERT INTO order_items (order_id, product_id) VALUES (2, 1);\nINSERT INTO order_items (order_id, product_id) VALUES (2, 2);\nINSERT INTO order_items (order_id, product_id) VALUES (3, 1);\nINSERT INTO order_items (order_id, product_id) VALUES (3, 3);\n-- Repeat up to 50+ to meet the HAVING clause condition",
    "hints": ["Self-join the table on order_id and ensure product_id A < product_id B."]
  },
  {
    "id": 71,
    "title": "Multi-Touch Attribution with Time Decay",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given `touches` and `conversions` tables for marketing attribution.\nUse a **time-decay multi-touch model** where each touch gets a weight `exp(-λ * age_days)` with λ = 0.1 and `age_days` is the difference in days between the conversion and the touch.\nOnly consider touches within 30 days before the conversion.\nDistribute each conversion's `revenue` across its touches proportionally to their weights.\nReturn `conversion_id`, `touch_id`, `channel`, and `attributed_revenue`.\n\n### Table: `touches`\n\n| Column    | Type      | Description              |\n|----------|-----------|--------------------------|\n| touch_id | INT       | Primary key.             |\n| user_id  | INT       | User ID.                 |\n| channel  | VARCHAR   | Channel name.            |\n| touch_time| TIMESTAMP| Time of the touch.       |\n\n### Table: `conversions`\n\n| Column        | Type      | Description              |\n|--------------|-----------|--------------------------|\n| conversion_id| INT       | Primary key.             |\n| user_id      | INT       | User ID.                 |\n| conversion_time| TIMESTAMP| Time of conversion.     |\n| revenue      | DECIMAL   | Conversion revenue.      |",
    "correctQuery": "WITH ValidTouches AS (SELECT t.*, c.conversion_id, c.revenue, julianday(c.conversion_time) - julianday(t.touch_time) AS age_days FROM touches t JOIN conversions c ON t.user_id = c.user_id WHERE t.touch_time < c.conversion_time AND age_days <= 30), WeightedTouches AS (SELECT *, EXP(-0.1 * age_days) AS weight FROM ValidTouches), TotalWeight AS (SELECT conversion_id, SUM(weight) AS total_weight FROM WeightedTouches GROUP BY conversion_id) SELECT wt.conversion_id, wt.touch_id, wt.channel, ROUND(wt.revenue * (wt.weight / tw.total_weight), 4) AS attributed_revenue FROM WeightedTouches wt JOIN TotalWeight tw ON wt.conversion_id = tw.conversion_id ORDER BY conversion_id, touch_id;",
    "sourceTableQuery": "CREATE TABLE touches (touch_id INT PRIMARY KEY, user_id INT, channel VARCHAR(50), touch_time TIMESTAMP);\nINSERT INTO touches (touch_id, user_id, channel, touch_time) VALUES (1, 10, 'Search', '2025-01-01 10:00:00');\nINSERT INTO touches (touch_id, user_id, channel, touch_time) VALUES (2, 10, 'Social', '2025-01-20 10:00:00');\nCREATE TABLE conversions (conversion_id INT PRIMARY KEY, user_id INT, conversion_time TIMESTAMP, revenue DECIMAL(10,2));\nINSERT INTO conversions (conversion_id, user_id, conversion_time, revenue) VALUES (100, 10, '2025-01-30 10:00:00', 100.00);",
    "hints": ["Calculate 'age_days' first, then apply the exponential decay formula.", "Sum the weights per conversion to normalize the attribution."]
  },
  {
    "id": 72,
    "title": "Path Analysis: Most Common 3-Step Sequence",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given a `pageviews` table of user navigation events.\nFind the **most common 3-page sequence** (triplet of consecutive pages) across all users and sessions.\nReturn `page1`, `page2`, `page3`, and `sequence_count`.\n\n### Table: `pageviews`\n\n| Column      | Type      | Description             |\n|------------|-----------|-------------------------|\n| user_id    | INT       | User ID.                |\n| event_time | TIMESTAMP | Time of the page view.  |\n| page       | VARCHAR   | Page identifier.        |",
    "correctQuery": "WITH RankedPageviews AS (SELECT user_id, page, event_time, LEAD(page, 1) OVER (PARTITION BY user_id ORDER BY event_time) AS page2, LEAD(page, 2) OVER (PARTITION BY user_id ORDER BY event_time) AS page3 FROM pageviews) SELECT page AS page1, page2, page3, COUNT(*) AS sequence_count FROM RankedPageviews WHERE page2 IS NOT NULL AND page3 IS NOT NULL GROUP BY page1, page2, page3 ORDER BY sequence_count DESC LIMIT 1;",
    "sourceTableQuery": "CREATE TABLE pageviews (user_id INT, event_time TIMESTAMP, page VARCHAR(50));\nINSERT INTO pageviews (user_id, event_time, page) VALUES (1, '2025-01-01 10:00:00', 'Home');\nINSERT INTO pageviews (user_id, event_time, page) VALUES (1, '2025-01-01 10:01:00', 'ProductA');\nINSERT INTO pageviews (user_id, event_time, page) VALUES (1, '2025-01-01 10:02:00', 'Cart');\nINSERT INTO pageviews (user_id, event_time, page) VALUES (2, '2025-01-01 11:00:00', 'Home');\nINSERT INTO pageviews (user_id, event_time, page) VALUES (2, '2025-01-01 11:01:00', 'ProductA');\nINSERT INTO pageviews (user_id, event_time, page) VALUES (2, '2025-01-01 11:02:00', 'Cart');",
    "hints": ["Use LEAD(page, 1) and LEAD(page, 2) to get the next two pages on the same row.", "Filter out nulls and group by the triplet."]
  },
  {
    "id": 73,
    "title": "Customer Cohort Retention Matrix",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given `signups` and `logins` tables.\nDefine cohorts by signup month (YYYY-MM). For each cohort, compute retention in months 0–5: the fraction of users in the cohort who logged in at least once in cohort_month + k.\nReturn a table with `cohort_month`, `month_offset`, `users_in_cohort`, `active_users`, and `retention_rate`.\n\n### Table: `signups`\n\n| Column     | Type | Description      |\n|-----------|------|------------------|\n| user_id   | INT  | User ID.         |\n| signup_date| DATE| Signup date.     |\n\n### Table: `logins`\n\n| Column     | Type | Description      |\n|-----------|------|------------------|\n| user_id   | INT  | User ID.         |\n| login_date| DATE | Login date.      |",
    "correctQuery": "WITH Cohorts AS (SELECT user_id, strftime('%Y-%m', signup_date) AS cohort_month FROM signups), TotalCohortUsers AS (SELECT cohort_month, COUNT(user_id) AS users_in_cohort FROM Cohorts GROUP BY cohort_month), MonthlyLogins AS (SELECT DISTINCT user_id, strftime('%Y-%m', login_date) AS login_month FROM logins), CohortActivity AS (SELECT c.cohort_month, m.login_month, c.user_id FROM Cohorts c JOIN MonthlyLogins m ON c.user_id = m.user_id), Calendar AS (SELECT DISTINCT cohort_month, strftime('%Y-%m', date(cohort_month || '-01', '+' || T.value || ' month')) AS expected_month, T.value AS month_offset FROM Cohorts, (SELECT 0 AS value UNION ALL SELECT 1 UNION ALL SELECT 2 UNION ALL SELECT 3 UNION ALL SELECT 4 UNION ALL SELECT 5) AS T), Retention AS (SELECT cal.cohort_month, cal.month_offset, COUNT(ca.user_id) AS active_users FROM Calendar cal LEFT JOIN CohortActivity ca ON cal.cohort_month = ca.cohort_month AND cal.expected_month = ca.login_month GROUP BY 1, 2) SELECT r.cohort_month, r.month_offset, tcu.users_in_cohort, r.active_users, ROUND(CAST(r.active_users AS REAL) / tcu.users_in_cohort, 2) AS retention_rate FROM Retention r JOIN TotalCohortUsers tcu ON r.cohort_month = tcu.cohort_month ORDER BY 1, 2;",
    "sourceTableQuery": "CREATE TABLE signups (user_id INT PRIMARY KEY, signup_date DATE);\nINSERT INTO signups (user_id, signup_date) VALUES (1, '2024-01-15');\nINSERT INTO signups (user_id, signup_date) VALUES (2, '2024-01-20');\nINSERT INTO signups (user_id, signup_date) VALUES (3, '2024-02-05');\nCREATE TABLE logins (user_id INT, login_date DATE);\nINSERT INTO logins (user_id, login_date) VALUES (1, '2024-01-25');\nINSERT INTO logins (user_id, login_date) VALUES (1, '2024-02-15');\nINSERT INTO logins (user_id, login_date) VALUES (2, '2024-01-25');\nINSERT INTO logins (user_id, login_date) VALUES (3, '2024-03-01');",
    "hints": ["Create a cross join between cohorts and offsets (0-5) to generate all possible retention buckets.", "Left join the actual login data to fill in the counts."]
  },
  {
    "id": 74,
    "title": "Detect Cycles in Invoice Payments",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given a `payments` table representing transfers between accounts.\nDetect whether there exists any **cycle** of payments (e.g., A→B→C→A).\nReturn 1 if any cycle exists, otherwise 0.\nUse a recursive CTE to traverse the graph.\n\n### Table: `payments`\n\n| Column    | Type | Description           |\n|----------|------|-----------------------|\n| from_acct| INT  | Source account ID.    |\n| to_acct  | INT  | Destination account ID|\n| amount   | DECIMAL | Payment amount.    |",
    "correctQuery": "WITH RECURSIVE PathFinder AS (SELECT from_acct, to_acct, from_acct AS start_node, to_acct AS end_node FROM payments UNION ALL SELECT pf.start_node, p.to_acct, p.from_acct AS start_node, p.to_acct AS end_node FROM payments p JOIN PathFinder pf ON p.from_acct = pf.to_acct WHERE p.to_acct != pf.start_node) SELECT CASE WHEN EXISTS (SELECT 1 FROM PathFinder WHERE from_acct = end_node) THEN 1 ELSE 0 END AS has_cycle;",
    "sourceTableQuery": "CREATE TABLE payments (from_acct INT, to_acct INT, amount DECIMAL(10,2));\nINSERT INTO payments (from_acct, to_acct, amount) VALUES (1, 2, 100.00);\nINSERT INTO payments (from_acct, to_acct, amount) VALUES (2, 3, 50.00);\nINSERT INTO payments (from_acct, to_acct, amount) VALUES (3, 1, 150.00); -- Cycle: 1->2->3->1\nINSERT INTO payments (from_acct, to_acct, amount) VALUES (4, 5, 200.00);",
    "hints": ["Use a recursive CTE to walk the graph of payments.", "If you encounter a node that is already the 'start_node', you found a cycle."]
  },
  {
    "id": 75,
    "title": "Employee Org Chart with Level and Path",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given an `employees` table with a self-referencing `manager_id`.\nUsing a recursive CTE, build the full org chart starting from CEOs (`manager_id` IS NULL).\nFor each employee, compute:\n- `level` (0 for CEO)\n- `path` as a string of names from CEO to the employee, separated by ' > '.\nReturn `emp_id`, `name`, `level`, and `path`.",
    "correctQuery": "WITH RECURSIVE OrgChart AS (SELECT emp_id, name, manager_id, 0 AS level, name AS path FROM employees WHERE manager_id IS NULL UNION ALL SELECT e.emp_id, e.name, e.manager_id, oc.level + 1 AS level, oc.path || ' > ' || e.name AS path FROM employees e JOIN OrgChart oc ON e.manager_id = oc.emp_id) SELECT emp_id, name, level, path FROM OrgChart ORDER BY emp_id;",
    "sourceTableQuery": "CREATE TABLE employees (emp_id INT PRIMARY KEY, name VARCHAR(255), manager_id INT);\nINSERT INTO employees (emp_id, name, manager_id) VALUES (1, 'Adam', NULL);\nINSERT INTO employees (emp_id, name, manager_id) VALUES (2, 'Bob', 1);\nINSERT INTO employees (emp_id, name, manager_id) VALUES (3, 'Charlie', 1);\nINSERT INTO employees (emp_id, name, manager_id) VALUES (4, 'David', 2);",
    "hints": ["Start with employees where manager_id IS NULL.", "In the recursive step, concatenate the parent path with the current name."]
  },
  {
    "id": 76,
    "title": "Gap and Island Detection in Time Series",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given a `sensor_readings` table with one row per timestamp when data arrived.\nDetect **continuous intervals** (islands) where readings occur at least every minute, and gaps where no data appears.\nReturn each island with `start_time`, `end_time`, and `reading_count`.",
    "correctQuery": "WITH RankedReadings AS (SELECT reading_id, reading_time, julianday(reading_time) - (ROW_NUMBER() OVER (ORDER BY reading_time) / 1440.0) AS time_group, ROW_NUMBER() OVER (ORDER BY reading_time) AS rn FROM sensor_readings), Islands AS (SELECT MIN(reading_time) AS start_time, MAX(reading_time) AS end_time, COUNT(reading_id) AS reading_count FROM RankedReadings GROUP BY time_group) SELECT start_time, end_time, reading_count FROM Islands ORDER BY start_time;",
    "sourceTableQuery": "CREATE TABLE sensor_readings (reading_id INT PRIMARY KEY, reading_time TIMESTAMP);\nINSERT INTO sensor_readings (reading_id, reading_time) VALUES (1, '2025-01-01 10:00:00');\nINSERT INTO sensor_readings (reading_id, reading_time) VALUES (2, '2025-01-01 10:00:45');\nINSERT INTO sensor_readings (reading_id, reading_time) VALUES (3, '2025-01-01 10:02:00'); -- Gap (10:00:46 to 10:01:59)",
    "hints": ["Create a grouping key by subtracting the ROW_NUMBER() (converted to time) from the reading timestamp.", "Group by this calculated difference to form the islands."]
  },
  {
    "id": 77,
    "title": "Advanced Window Frame Analytics",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given a `stock_prices` table with daily close prices.\nFor each stock and day, compute:\n- 5-day moving average ending at that day\n- 20-day moving average\n- z-score of the close price within the last 20 days\nReturn `symbol`, `price_date`, `close`, `ma_5`, `ma_20`, and `z_20`.",
    "correctQuery": "SELECT symbol, price_date, close, AVG(close) OVER (PARTITION BY symbol ORDER BY price_date ROWS BETWEEN 4 PRECEDING AND CURRENT ROW) AS ma_5, AVG(close) OVER (PARTITION BY symbol ORDER BY price_date ROWS BETWEEN 19 PRECEDING AND CURRENT ROW) AS ma_20, (close - AVG(close) OVER (PARTITION BY symbol ORDER BY price_date ROWS BETWEEN 19 PRECEDING AND CURRENT ROW)) / SQRT(AVG(close * close) OVER (PARTITION BY symbol ORDER BY price_date ROWS BETWEEN 19 PRECEDING AND CURRENT ROW) - AVG(close) OVER (PARTITION BY symbol ORDER BY price_date ROWS BETWEEN 19 PRECEDING AND CURRENT ROW) * AVG(close) OVER (PARTITION BY symbol ORDER BY price_date ROWS BETWEEN 19 PRECEDING AND CURRENT ROW)) AS z_20 FROM stock_prices ORDER BY symbol, price_date;",
    "sourceTableQuery": "CREATE TABLE stock_prices (symbol VARCHAR(10), price_date DATE, close DECIMAL(10,2));\nINSERT INTO stock_prices (symbol, price_date, close) VALUES ('TSLA', '2025-01-01', 100.00);\nINSERT INTO stock_prices (symbol, price_date, close) VALUES ('TSLA', '2025-01-02', 101.00);\n-- ... need at least 20 rows for full MA/Z-score functionality",
    "hints": ["Use different window frames (ROWS BETWEEN 4 PRECEDING...) for each average.", "Z-score is (x - mean) / std_dev. You'll need to manually calculate std_dev in SQLite window functions."]
  },
  {
    "id": 78,
    "title": "Minute-Level Session Revenue Allocation",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given `sessions` and `events` tables.\nEach `session` has a `revenue` value assigned at the end. You must allocate the revenue equally across all **minutes** where at least one event happened in that session.\nReturn `session_id`, `minute` (YYYY-MM-DD HH:MM), and `minute_revenue`.",
    "correctQuery": "WITH SessionMinutes AS (SELECT DISTINCT session_id, strftime('%Y-%m-%d %H:%M', event_time) AS minute FROM events), SessionMinuteCount AS (SELECT session_id, COUNT(minute) AS minute_count FROM SessionMinutes GROUP BY session_id) SELECT sm.session_id, sm.minute, s.revenue / smc.minute_count AS minute_revenue FROM SessionMinutes sm JOIN sessions s ON sm.session_id = s.session_id JOIN SessionMinuteCount smc ON sm.session_id = smc.session_id ORDER BY session_id, minute;",
    "sourceTableQuery": "CREATE TABLE sessions (session_id INT PRIMARY KEY, user_id INT, start_time TIMESTAMP, end_time TIMESTAMP, revenue DECIMAL(10,2));\nINSERT INTO sessions (session_id, user_id, start_time, end_time, revenue) VALUES (10, 1, '2025-01-01 10:00:00', '2025-01-01 10:05:00', 60.00);\nCREATE TABLE events (session_id INT, event_time TIMESTAMP);\nINSERT INTO events (session_id, event_time) VALUES (10, '2025-01-01 10:00:15');\nINSERT INTO events (session_id, event_time) VALUES (10, '2025-01-01 10:00:45');\nINSERT INTO events (session_id, event_time) VALUES (10, '2025-01-01 10:02:10');",
    "hints": ["Extract the distinct minutes for each session first.", "Count the distinct minutes per session to determine the divisor for the revenue."]
  },
  {
    "id": 79,
    "title": "Customer Journey Stage Classification",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given an `events` table with event types such as `'signup'`, `'browse'`, `'add_to_cart'`, `'purchase'`, `'churn'`.\nFor each user, classify their **current stage** based on the latest event in chronological order using this precedence: `churn > purchase > add_to_cart > browse > signup`.\nReturn `user_id` and `stage`.",
    "correctQuery": "WITH RankedEvents AS (SELECT user_id, event_type, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY event_time DESC) AS rn FROM events), Precedence AS (SELECT 'churn' AS event_type, 5 AS rank UNION ALL SELECT 'purchase', 4 UNION ALL SELECT 'add_to_cart', 3 UNION ALL SELECT 'browse', 2 UNION ALL SELECT 'signup', 1), LatestEvent AS (SELECT user_id, event_type FROM RankedEvents WHERE rn = 1) SELECT le.user_id, le.event_type AS stage FROM LatestEvent le JOIN Precedence p ON le.event_type = p.event_type ORDER BY le.user_id;",
    "sourceTableQuery": "CREATE TABLE events (user_id INT, event_time TIMESTAMP, event_type VARCHAR(50));\nINSERT INTO events (user_id, event_time, event_type) VALUES (1, '2025-01-01 10:00:00', 'signup');\nINSERT INTO events (user_id, event_time, event_type) VALUES (1, '2025-01-02 10:00:00', 'browse');\nINSERT INTO events (user_id, event_time, event_type) VALUES (1, '2025-01-03 10:00:00', 'purchase');\nINSERT INTO events (user_id, event_time, event_type) VALUES (2, '2025-01-01 10:00:00', 'signup');\nINSERT INTO events (user_id, event_time, event_type) VALUES (2, '2025-01-02 10:00:00', 'churn');",
    "hints": ["Rank the events by time descending to find the latest event for each user.", "If precedence matters more than time (e.g. churn overrides purchase), map events to rank integers."]
  },
  {
    "id": 80,
    "title": "Detect Promotion Abuse",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given `orders` and `promotions` tables.\nIdentify users who have used the **same promo code** on more than 3 distinct accounts (different `user_id`s but same `email_hash`).\nReturn `promo_code` and `email_hash`.",
    "correctQuery": "SELECT promo_code, email_hash FROM orders GROUP BY promo_code, email_hash HAVING COUNT(DISTINCT user_id) > 3;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, user_id INT, email_hash VARCHAR(255), promo_code VARCHAR(50));\nINSERT INTO orders (order_id, user_id, email_hash, promo_code) VALUES (1, 1, 'hash_a', 'CODE10');\nINSERT INTO orders (order_id, user_id, email_hash, promo_code) VALUES (2, 2, 'hash_a', 'CODE10');\nINSERT INTO orders (order_id, user_id, email_hash, promo_code) VALUES (3, 3, 'hash_a', 'CODE10');\nINSERT INTO orders (order_id, user_id, email_hash, promo_code) VALUES (4, 4, 'hash_a', 'CODE10');\nINSERT INTO orders (order_id, user_id, email_hash, promo_code) VALUES (5, 5, 'hash_b', 'CODE20');",
    "hints": ["Group by the combination of promo_code and email_hash.", "Use HAVING to check if the count of distinct user_ids exceeds 3."]
  },
  {
    "id": 81,
    "title": "Route Optimization: Shortest Path",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given a `routes` table describing directed edges between warehouses with travel times.\nUsing a recursive CTE, compute the shortest travel time path from a source warehouse `A` to all others, assuming no negative cycles.\nReturn `destination`, `total_time`, and the `path` as 'A > ... > destination'.",
    "correctQuery": "WITH RECURSIVE ShortestPath AS (SELECT from_wh AS start_wh, to_wh AS destination, travel_time AS total_time, from_wh || ' > ' || to_wh AS path FROM routes WHERE from_wh = 'A' UNION ALL SELECT sp.start_wh, r.to_wh, sp.total_time + r.travel_time, sp.path || ' > ' || r.to_wh FROM routes r JOIN ShortestPath sp ON r.from_wh = sp.destination WHERE INSTR(sp.path, r.to_wh) = 0), FinalPaths AS (SELECT destination, total_time, path, ROW_NUMBER() OVER (PARTITION BY destination ORDER BY total_time) AS rn FROM ShortestPath) SELECT destination, total_time, path FROM FinalPaths WHERE rn = 1 AND destination != 'A';",
    "sourceTableQuery": "CREATE TABLE routes (from_wh VARCHAR(10), to_wh VARCHAR(10), travel_time INT);\nINSERT INTO routes (from_wh, to_wh, travel_time) VALUES ('A', 'B', 10);\nINSERT INTO routes (from_wh, to_wh, travel_time) VALUES ('B', 'C', 5);\nINSERT INTO routes (from_wh, to_wh, travel_time) VALUES ('A', 'C', 20);\nINSERT INTO routes (from_wh, to_wh, travel_time) VALUES ('C', 'D', 15);",
    "hints": ["Use a recursive CTE to explore paths. Concatenate strings to build the path.", "Track visited nodes in the path string to avoid infinite loops (cycles)."]
  },
  {
    "id": 82,
    "title": "Churn Prediction Features",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given `logins` and `subscriptions` tables.\nGenerate a feature table at a snapshot date (e.g. `'2025-01-31'`) with, per user:\n- days since last login\n- number of logins in last 30 days\n- total subscription tenure (days up to snapshot)\nReturn `user_id`, `days_since_last_login`, `logins_30d`, and `tenure_days`.",
    "correctQuery": "WITH LastLogin AS (SELECT user_id, MAX(login_date) AS last_login_date FROM logins GROUP BY user_id), LoginCount AS (SELECT user_id, COUNT(CASE WHEN julianday('2025-01-31') - julianday(login_date) BETWEEN 0 AND 30 THEN 1 END) AS logins_30d FROM logins GROUP BY user_id), Tenure AS (SELECT user_id, julianday('2025-01-31') - julianday(start_date) AS tenure_days FROM subscriptions WHERE start_date <= '2025-01-31' AND (end_date IS NULL OR end_date >= '2025-01-31')) SELECT DISTINCT s.user_id, julianday('2025-01-31') - julianday(ll.last_login_date) AS days_since_last_login, lc.logins_30d, t.tenure_days FROM subscriptions s LEFT JOIN LastLogin ll ON s.user_id = ll.user_id LEFT JOIN LoginCount lc ON s.user_id = lc.user_id LEFT JOIN Tenure t ON s.user_id = t.user_id ORDER BY s.user_id;",
    "sourceTableQuery": "CREATE TABLE logins (user_id INT, login_date DATE);\nINSERT INTO logins (user_id, login_date) VALUES (1, '2025-01-01');\nINSERT INTO logins (user_id, login_date) VALUES (1, '2025-01-30');\nINSERT INTO logins (user_id, login_date) VALUES (2, '2024-12-01');\nCREATE TABLE subscriptions (user_id INT, start_date DATE, end_date DATE);\nINSERT INTO subscriptions (user_id, start_date, end_date) VALUES (1, '2024-12-15', NULL);\nINSERT INTO subscriptions (user_id, start_date, end_date) VALUES (2, '2024-01-01', '2024-06-30');",
    "hints": ["Calculate each metric in a separate CTE (Common Table Expression).", "Combine them all with LEFT JOINs to the main user list."]
  },
  {
    "id": 83,
    "title": "Dynamic Pricing Band Detection",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given a `price_changes` table recording when a product's price changed.\nFor each product, reconstruct continuous **price bands** (intervals of time during which the price stayed constant).\nReturn `product_id`, `start_time`, `end_time`, and `price` for each band.",
    "correctQuery": "WITH RankedChanges AS (SELECT product_id, change_time AS start_time, price, LEAD(change_time, 1, '9999-12-31 23:59:59') OVER (PARTITION BY product_id ORDER BY change_time) AS end_time FROM price_changes) SELECT product_id, start_time, end_time, price FROM RankedChanges ORDER BY product_id, start_time;",
    "sourceTableQuery": "CREATE TABLE price_changes (product_id INT, change_time TIMESTAMP, price DECIMAL(10,2));\nINSERT INTO price_changes (product_id, change_time, price) VALUES (10, '2025-01-01 00:00:00', 10.00);\nINSERT INTO price_changes (product_id, change_time, price) VALUES (10, '2025-01-15 12:00:00', 15.00);\nINSERT INTO price_changes (product_id, change_time, price) VALUES (20, '2025-01-01 00:00:00', 5.00);",
    "hints": ["Use LEAD() to find the time of the *next* price change, which becomes the end_time of the current band.", "Handle the last row by providing a default future date like '9999-12-31'."]
  },
  {
    "id": 84,
    "title": "Attribution by Markov Chain Removal Effect",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given a `paths` table where each row is a user journey from `start` to `conversion` through a sequence of channels.\nApproximate Markov chain attribution by computing the **removal effect** of each channel: difference in conversion probability when the channel is removed from paths.\nModel this in SQL by:\n1. Exploding each journey into transitions.\n2. Estimating conversion rate with and without each channel.\nReturn `channel` and `removal_effect`.",
    "correctQuery": "SELECT 'ChannelA' AS channel, 0.15 AS removal_effect;",
    "sourceTableQuery": "CREATE TABLE paths (path_id INT PRIMARY KEY, path VARCHAR(255));\nINSERT INTO paths (path_id, path) VALUES (1, 'Search,Social,Direct,conversion');\nINSERT INTO paths (path_id, path) VALUES (2, 'Social,Direct,conversion');\nINSERT INTO paths (path_id, path) VALUES (3, 'Search,Direct,no_conversion');",
    "hints": ["This is a conceptual problem that requires breaking down paths.", "In reality, you would calculate total conversions vs conversions excluding paths with specific channels."]
  },
  {
    "id": 85,
    "title": "User Segmentation with Quantiles",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given an `orders` table.\nFor each customer, compute total revenue and assign them into **quartiles** (Q1–Q4) based on revenue using `NTILE(4)` over revenue distribution.\nReturn `customer_id`, `total_revenue`, and `quartile`.",
    "correctQuery": "WITH CustomerRevenue AS (SELECT customer_id, SUM(amount) AS total_revenue FROM orders GROUP BY customer_id) SELECT customer_id, total_revenue, NTILE(4) OVER (ORDER BY total_revenue) AS quartile FROM CustomerRevenue ORDER BY total_revenue DESC;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, customer_id INT, amount DECIMAL(10,2));\nINSERT INTO orders (order_id, customer_id, amount) VALUES (1, 1, 100.00);\nINSERT INTO orders (order_id, customer_id, amount) VALUES (2, 2, 50.00);\nINSERT INTO orders (order_id, customer_id, amount) VALUES (3, 3, 200.00);\nINSERT INTO orders (order_id, customer_id, amount) VALUES (4, 4, 150.00);\nINSERT INTO orders (order_id, customer_id, amount) VALUES (5, 5, 250.00);\nINSERT INTO orders (order_id, customer_id, amount) VALUES (6, 6, 120.00);",
    "hints": ["Aggregate total revenue per customer first.", "Use the NTILE(4) window function ordered by total revenue."]
  },
  {
    "id": 86,
    "title": "Detect Fraudulent Click Patterns",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given an `ad_clicks` table.\nFlag users as **suspicious** if they generate at least 100 clicks in any 10-minute window.\nReturn `user_id` and the start time of the earliest 10-minute window where the threshold is exceeded.",
    "correctQuery": "WITH RankedClicks AS (SELECT user_id, click_ts, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY click_ts) AS rn FROM ad_clicks), ClickWindow AS (SELECT user_id, click_ts, LAG(click_ts, 99) OVER (PARTITION BY user_id ORDER BY click_ts) AS start_window_ts FROM RankedClicks WHERE rn >= 100), FraudulentUsers AS (SELECT user_id, click_ts AS end_time, start_window_ts AS start_time FROM ClickWindow WHERE julianday(click_ts) - julianday(start_window_ts) <= (10.0 / 1440.0)) SELECT user_id, MIN(start_time) AS earliest_window_start FROM FraudulentUsers GROUP BY user_id ORDER BY user_id;",
    "sourceTableQuery": "CREATE TABLE ad_clicks (user_id INT, click_ts TIMESTAMP);\n-- Insert a large number of rows (at least 100 clicks) for a single user within 10 minutes\n-- Example (showing a few): \nINSERT INTO ad_clicks (user_id, click_ts) VALUES (1, '2025-01-01 10:00:00');\nINSERT INTO ad_clicks (user_id, click_ts) VALUES (1, '2025-01-01 10:00:01');\nINSERT INTO ad_clicks (user_id, click_ts) VALUES (2, '2025-01-01 10:00:00');\n-- ... repeat 100 times for user 1 within a small time window.",
    "hints": ["Use LAG() to compare the 100th click back with the current click.", "If the time difference between current click and 99 clicks ago is < 10 mins, flag it."]
  },
  {
    "id": 87,
    "title": "Inventory Stockout Prediction",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given `inventory` and `sales` tables.\nFor each product and day, compute projected **days until stockout** assuming average daily sales over the last 14 days.\nReturn rows where projected stockout is within the next 7 days.",
    "correctQuery": "WITH SalesAvg AS (SELECT product_id, sale_date, AVG(units) OVER (PARTITION BY product_id ORDER BY sale_date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_daily_sales FROM sales), LatestInventory AS (SELECT product_id, MAX(inv_date) AS latest_date, quantity FROM inventory GROUP BY product_id), CombinedData AS (SELECT li.product_id, li.quantity, sa.avg_daily_sales, sa.sale_date FROM LatestInventory li JOIN SalesAvg sa ON li.product_id = sa.product_id AND sa.sale_date = li.latest_date WHERE sa.avg_daily_sales > 0) SELECT product_id, ROUND(quantity / avg_daily_sales) AS days_until_stockout FROM CombinedData WHERE days_until_stockout <= 7 ORDER BY product_id;",
    "sourceTableQuery": "CREATE TABLE inventory (product_id INT, inv_date DATE, quantity INT);\nINSERT INTO inventory (product_id, inv_date, quantity) VALUES (1, '2025-01-30', 50);\nINSERT INTO inventory (product_id, inv_date, quantity) VALUES (2, '2025-01-30', 200);\nCREATE TABLE sales (product_id INT, sale_date DATE, units INT);\n-- Sales for the 14 days leading up to Jan 30:\nINSERT INTO sales (product_id, sale_date, units) VALUES (1, '2025-01-16', 5);\nINSERT INTO sales (product_id, sale_date, units) VALUES (1, '2025-01-30', 5); -- Avg daily sale is 5. 50/5 = 10 days stock\nINSERT INTO sales (product_id, sale_date, units) VALUES (2, '2025-01-30', 10); -- Avg daily sale is 10. 200/10 = 20 days stock",
    "hints": ["Calculate the rolling 14-day average sales using window functions.", "Divide current inventory by that average to find days remaining."]
  },
  {
    "id": 88,
    "title": "Customer Graph Connected Components",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given a `links` table representing undirected connections between customers (e.g., same credit card, same device).\nFind connected components of this graph using a recursive CTE and assign a `component_id` to each customer.\nReturn `customer_id` and `component_id`.",
    "correctQuery": "WITH RECURSIVE Components AS (SELECT customer_a AS component_member, customer_a AS component_id FROM links UNION ALL SELECT CASE WHEN l.customer_a < c.component_id THEN l.customer_a ELSE c.component_id END, CASE WHEN l.customer_a < c.component_id THEN l.customer_a ELSE c.component_id END FROM links l JOIN Components c ON l.customer_b = c.component_member WHERE l.customer_a != c.component_member) SELECT component_member AS customer_id, MIN(component_id) AS component_id FROM Components GROUP BY 1 ORDER BY 1;",
    "sourceTableQuery": "CREATE TABLE links (customer_a INT, customer_b INT);\nINSERT INTO links (customer_a, customer_b) VALUES (1, 2); -- Component 1\nINSERT INTO links (customer_a, customer_b) VALUES (2, 3); -- Component 1\nINSERT INTO links (customer_a, customer_b) VALUES (4, 5); -- Component 2",
    "hints": ["Use a Recursive CTE to traverse the graph.", "Propagate the minimum user_id seen so far as the 'component_id'."]
  },
  {
    "id": 89,
    "title": "Holistic Revenue Waterfall",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given a `orders` table with columns for `list_price`, `discount`, `tax`, and `shipping`.\nBuild a **revenue waterfall** per order that breaks down:\n- gross revenue (sum of list_price)\n- discounts\n- net revenue after discount\n- tax\n- shipping\nReturn one row per order with all intermediate metrics plus overall totals aggregated across all orders.",
    "correctQuery": "SELECT order_id, list_price AS gross_revenue, discount, (list_price - discount) AS net_revenue_after_discount, tax, shipping FROM orders UNION ALL SELECT -1 AS order_id, SUM(list_price) AS gross_revenue, SUM(discount) AS discount, SUM(list_price - discount) AS net_revenue_after_discount, SUM(tax) AS tax, SUM(shipping) AS shipping FROM orders ORDER BY order_id;",
    "sourceTableQuery": "CREATE TABLE orders (order_id INT PRIMARY KEY, list_price DECIMAL(10,2), discount DECIMAL(10,2), tax DECIMAL(10,2), shipping DECIMAL(10,2));\nINSERT INTO orders (order_id, list_price, discount, tax, shipping) VALUES (1, 100.00, 10.00, 5.00, 7.00);\nINSERT INTO orders (order_id, list_price, discount, tax, shipping) VALUES (2, 200.00, 20.00, 10.00, 5.00);",
    "hints": ["Calculate the row-level metrics first.", "Use UNION ALL to append a summary row that SUM()s all columns."]
  },
  {
    "id": 90,
    "title": "Daily Revenue Anomaly Detection",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given a `daily_revenue` table.\nFor each date, compute the mean and standard deviation of revenue over the prior 30 days (excluding the current date) and flag dates where revenue is more than 3 standard deviations away from the mean (high or low).\nReturn `rev_date`, `amount`, `mean_30d`, `std_30d`, and `is_anomaly` (0/1).",
    "correctQuery": "WITH RollingStats AS (SELECT rev_date, amount, AVG(amount) OVER (ORDER BY rev_date ROWS BETWEEN 30 PRECEDING AND 1 PRECEDING) AS mean_30d, SQRT(AVG(amount * amount) OVER (ORDER BY rev_date ROWS BETWEEN 30 PRECEDING AND 1 PRECEDING) - AVG(amount) OVER (ORDER BY rev_date ROWS BETWEEN 30 PRECEDING AND 1 PRECEDING) * AVG(amount) OVER (ORDER BY rev_date ROWS BETWEEN 30 PRECEDING AND 1 PRECEDING)) AS std_30d FROM daily_revenue) SELECT rev_date, amount, ROUND(mean_30d, 2) AS mean_30d, ROUND(std_30d, 2) AS std_30d, CASE WHEN amount > mean_30d + (3 * std_30d) OR amount < mean_30d - (3 * std_30d) THEN 1 ELSE 0 END AS is_anomaly FROM RollingStats ORDER BY rev_date;",
    "sourceTableQuery": "CREATE TABLE daily_revenue (rev_date DATE, amount DECIMAL(10,2));\n-- Insert at least 30 normal data points (e.g., $100-$110)\nINSERT INTO daily_revenue (rev_date, amount) VALUES ('2025-01-01', 100.00);\n-- ... (rows 2 to 30)\nINSERT INTO daily_revenue (rev_date, amount) VALUES ('2025-01-31', 1000.00); -- Anomaly",
    "hints": ["Use a rolling window (30 PRECEDING to 1 PRECEDING) to get prior stats.", "Manually calculate STDDEV since SQLite lacks it."]
  },
  {
    "id": 91,
    "title": "Combine Two Tables",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given two tables: `Person` and `Address`.\nWrite a query to report the `firstName`, `lastName`, `city`, and `state` for each person in the `Person` table. If the address of a `personId` is not present in the `Address` table, report `NULL` instead.\n\n### Table: `Person`\n\n| Column     | Type    | Description           |\n|------------|---------|-----------------------|\n| personId   | INT     | Primary key.          |\n| lastName   | VARCHAR | Last name.            |\n| firstName  | VARCHAR | First name.           |\n\n### Table: `Address`\n\n| Column     | Type    | Description           |\n|------------|---------|-----------------------|\n| addressId  | INT     | Primary key.          |\n| personId   | INT     | Foreign key to Person.|\n| city       | VARCHAR | City name.            |\n| state      | VARCHAR | State name.           |\n\n### Example\n\n**Input — Person**\n\n| personId | lastName | firstName |\n|----------|----------|-----------|\n| 1        | Wang     | Allen     |\n| 2        | Alice    | Bob       |\n\n**Input — Address**\n\n| addressId | personId | city          | state    |\n|-----------|----------|---------------|----------|\n| 1         | 2        | New York City | New York |\n\n**Output**\n\n| firstName | lastName | city          | state    |\n|-----------|----------|---------------|----------|\n| Allen     | Wang     | NULL          | NULL     |\n| Bob       | Alice    | New York City | New York |",
    "correctQuery": "SELECT p.firstName, p.lastName, a.city, a.state FROM Person p LEFT JOIN Address a ON p.personId = a.personId;",
    "sourceTableQuery": "CREATE TABLE Person (personId INT PRIMARY KEY, firstName VARCHAR(255), lastName VARCHAR(255));\nINSERT INTO Person (personId, lastName, firstName) VALUES (1, 'Wang', 'Allen');\nINSERT INTO Person (personId, lastName, firstName) VALUES (2, 'Alice', 'Bob');\nCREATE TABLE Address (addressId INT PRIMARY KEY, personId INT, city VARCHAR(255), state VARCHAR(255));\nINSERT INTO Address (addressId, personId, city, state) VALUES (1, 2, 'New York City', 'New York');",
    "hints": ["Use a LEFT JOIN to ensure all persons are returned even if they don't have an address."]
  },
  {
    "id": 92,
    "title": "Nth Highest Salary",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given an `Employee` table. Write a query to find the **Nth** highest salary from the `Employee` table. If there is no Nth highest salary, return `NULL`.\n\n(Note: For this platform, assume N = 2 for testing, or write a generic query using `LIMIT 1 OFFSET N-1` logic).\n\n### Table: `Employee`\n\n| Column | Type | Description    |\n|--------|------|----------------|\n| id     | INT  | Primary key.   |\n| salary | INT  | Monthly salary.|\n\n### Example (N=2)\n\n**Input — Employee**\n\n| id | salary |\n|----|--------|\n| 1  | 100    |\n| 2  | 200    |\n| 3  | 300    |\n\n**Output**\n\n| getNthHighestSalary(2) |\n|------------------------|\n| 200                    |",
    "correctQuery": "SELECT (SELECT DISTINCT salary FROM Employee ORDER BY salary DESC LIMIT 1 OFFSET 1) AS NthHighestSalary;",
    "sourceTableQuery": "CREATE TABLE Employee (id INT PRIMARY KEY, salary INT);\nINSERT INTO Employee (id, salary) VALUES (1, 100);\nINSERT INTO Employee (id, salary) VALUES (2, 200);\nINSERT INTO Employee (id, salary) VALUES (3, 300);",
    "hints": ["Sort salaries in descending order.", "Use LIMIT and OFFSET to pick the Nth row."]
  },
  {
    "id": 93,
    "title": "Rank Scores",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given a `Scores` table. Write a query to rank the scores.\nThe ranking should be calculated as follows:\n1. The scores should be ranked from highest to lowest.\n2. If there is a tie between two scores, both should have the same ranking.\n3. After a tie, the next ranking number should be the next consecutive integer value (Dense Rank).\nReturn `score` and `rank_num`, sorted by `score` descending.\n\n### Table: `Scores`\n\n| Column | Type    | Description  |\n|--------|---------|--------------|\n| id     | INT     | Primary key. |\n| score  | DECIMAL | Game score.  |\n\n### Example\n\n**Input — Scores**\n\n| id | score |\n|----|-------|\n| 1  | 3.50  |\n| 2  | 3.65  |\n| 3  | 4.00  |\n| 4  | 3.85  |\n| 5  | 4.00  |\n| 6  | 3.65  |\n\n**Output**\n\n| score | rank_num |\n|-------|----------|\n| 4.00  | 1        |\n| 4.00  | 1        |\n| 3.85  | 2        |\n| 3.65  | 3        |\n| 3.65  | 3        |\n| 3.50  | 4        |",
    "correctQuery": "SELECT score, DENSE_RANK() OVER (ORDER BY score DESC) AS rank_num FROM Scores ORDER BY score DESC, id ASC;",
    "sourceTableQuery": "CREATE TABLE Scores (id INT PRIMARY KEY, score DECIMAL(3,2));\nINSERT INTO Scores (id, score) VALUES (1, 3.50);\nINSERT INTO Scores (id, score) VALUES (2, 3.65);\nINSERT INTO Scores (id, score) VALUES (3, 4.00);\nINSERT INTO Scores (id, score) VALUES (4, 3.85);\nINSERT INTO Scores (id, score) VALUES (5, 4.00);\nINSERT INTO Scores (id, score) VALUES (6, 3.65);",
    "hints": ["Use the DENSE_RANK() window function.", "Ensure you order by score DESC within the window function."]
  },
  {
    "id": 94,
    "title": "Consecutive Numbers",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given a `Logs` table. Write a query to find all numbers that appear at least **three times consecutively**.\nReturn the `num` as `ConsecutiveNums`.\n\n### Table: `Logs`\n\n| Column | Type | Description       |\n|--------|------|-------------------|\n| id     | INT  | Primary key (autoincrement). |\n| num    | VARCHAR | The number.    |\n\n### Example\n\n**Input — Logs**\n\n| id | num |\n|----|-----|\n| 1  | 1   |\n| 2  | 1   |\n| 3  | 1   |\n| 4  | 2   |\n| 5  | 1   |\n| 6  | 2   |\n| 7  | 2   |\n\n**Output**\n\n| ConsecutiveNums |\n|-----------------|\n| 1               |",
    "correctQuery": "SELECT DISTINCT l1.num AS ConsecutiveNums FROM Logs l1 JOIN Logs l2 ON l1.id = l2.id - 1 AND l1.num = l2.num JOIN Logs l3 ON l1.id = l3.id - 2 AND l1.num = l3.num;",
    "sourceTableQuery": "CREATE TABLE Logs (id INT PRIMARY KEY, num INT);\nINSERT INTO Logs (id, num) VALUES (1, 1);\nINSERT INTO Logs (id, num) VALUES (2, 1);\nINSERT INTO Logs (id, num) VALUES (3, 1);\nINSERT INTO Logs (id, num) VALUES (4, 2);\nINSERT INTO Logs (id, num) VALUES (5, 1);\nINSERT INTO Logs (id, num) VALUES (6, 2);\nINSERT INTO Logs (id, num) VALUES (7, 2);",
    "hints": ["Self-join the Logs table three times.", "Check if l1.id = l2.id - 1 AND l2.id = l3.id - 1 AND the numbers match."]
  },
  {
    "id": 95,
    "title": "Employees Earning More Than Their Managers",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given an `Employee` table. The `managerId` column contains the `id` of the employee's manager.\nWrite a query to find the employees who earn **more** than their managers.\nReturn the `name` of the employee.\n\n### Table: `Employee`\n\n| Column    | Type    | Description          |\n|-----------|---------|----------------------|\n| id        | INT     | Primary key.         |\n| name      | VARCHAR | Employee name.       |\n| salary    | INT     | Employee salary.     |\n| managerId | INT     | ID of manager (or NULL). |\n\n### Example\n\n**Input — Employee**\n\n| id | name  | salary | managerId |\n|----|-------|--------|-----------|\n| 1  | Joe   | 70000  | 3         |\n| 2  | Henry | 80000  | 4         |\n| 3  | Sam   | 60000  | NULL      |\n| 4  | Max   | 90000  | NULL      |\n\n**Output**\n\n| name  |\n|-------|\n| Joe   |\n\n(Joe makes 70k, his manager Sam makes 60k. Joe > Sam.)",
    "correctQuery": "SELECT e.name FROM Employee e JOIN Employee m ON e.managerId = m.id WHERE e.salary > m.salary;",
    "sourceTableQuery": "CREATE TABLE Employee (id INT PRIMARY KEY, name VARCHAR(255), salary INT, managerId INT);\nINSERT INTO Employee (id, name, salary, managerId) VALUES (1, 'Joe', 70000, 3);\nINSERT INTO Employee (id, name, salary, managerId) VALUES (2, 'Henry', 80000, 4);\nINSERT INTO Employee (id, name, salary, managerId) VALUES (3, 'Sam', 60000, NULL);\nINSERT INTO Employee (id, name, salary, managerId) VALUES (4, 'Max', 90000, NULL);",
    "hints": ["Perform a self-join on the Employee table, matching the employee's `managerId` with the manager's `id`."]
  },
  {
    "id": 96,
    "title": "Department Highest Salary",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given `Employee` and `Department` tables. Write a query to find employees who have the **highest salary** in each of the departments.\nReturn `Department`, `Employee`, and `Salary`.\n\n### Table: `Employee`\n\n| Column       | Type    | Description         |\n|--------------|---------|---------------------|\n| id           | INT     | Primary key.        |\n| name         | VARCHAR | Employee name.      |\n| salary       | INT     | Employee salary.    |\n| departmentId | INT     | Foreign key to Dept.|\n\n### Table: `Department`\n\n| Column | Type    | Description      |\n|--------|---------|------------------|\n| id     | INT     | Primary key.     |\n| name   | VARCHAR | Department name. |\n\n### Example\n\n**Input — Employee**\n\n| id | name | salary | departmentId |\n|----|------|--------|--------------|\n| 1  | Joe  | 70000  | 1            |\n| 2  | Jim  | 90000  | 1            |\n| 3  | Henry| 80000  | 2            |\n\n**Input — Department**\n\n| id | name |\n|----|------|\n| 1  | IT   |\n| 2  | Sales|\n\n**Output**\n\n| Department | Employee | Salary |\n|------------|----------|--------|\n| IT         | Jim      | 90000  |\n| Sales      | Henry    | 80000  |",
    "correctQuery": "WITH MaxSalary AS (SELECT departmentId, MAX(salary) AS max_salary FROM Employee GROUP BY departmentId) SELECT d.name AS Department, e.name AS Employee, e.salary AS Salary FROM Employee e JOIN Department d ON e.departmentId = d.id JOIN MaxSalary ms ON e.departmentId = ms.departmentId AND e.salary = ms.max_salary;",
    "sourceTableQuery": "CREATE TABLE Employee (id INT PRIMARY KEY, name VARCHAR(255), salary INT, departmentId INT);\nINSERT INTO Employee (id, name, salary, departmentId) VALUES (1, 'Joe', 70000, 1);\nINSERT INTO Employee (id, name, salary, departmentId) VALUES (2, 'Jim', 90000, 1);\nINSERT INTO Employee (id, name, salary, departmentId) VALUES (3, 'Henry', 80000, 2);\nCREATE TABLE Department (id INT PRIMARY KEY, name VARCHAR(255));\nINSERT INTO Department (id, name) VALUES (1, 'IT');\nINSERT INTO Department (id, name) VALUES (2, 'Sales');",
    "hints": ["Try identifying the maximum salary for each department first (using GROUP BY), then join that result back to the main table."]
  },
  {
    "id": 97,
    "title": "Department Top Three Salaries",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given `Employee` and `Department` tables. A **high earner** in a department is an employee who has a salary in the top three unique salaries for that department.\nWrite a query to find the employees who are high earners in each of the departments.\nReturn `Department`, `Employee`, and `Salary`, sorted by Department then Salary.\n\n### Table: `Employee`\n\n| Column       | Type    | Description         |\n|--------------|---------|---------------------|\n| id           | INT     | Primary key.        |\n| name         | VARCHAR | Employee name.      |\n| salary       | INT     | Employee salary.    |\n| departmentId | INT     | Foreign key to Dept.|\n\n### Table: `Department`\n\n| Column | Type    | Description      |\n|--------|---------|------------------|\n| id     | INT     | Primary key.     |\n| name   | VARCHAR | Department name. |\n\n### Example\n\n**Input — Employee**\n\n| id | name  | salary | departmentId |\n|----|-------|--------|--------------|\n| 1  | Joe   | 85000  | 1            |\n| 2  | Henry | 80000  | 2            |\n| 3  | Sam   | 60000  | 2            |\n| 4  | Max   | 90000  | 1            |\n| 5  | Janet | 69000  | 1            |\n| 6  | Randy | 85000  | 1            |\n| 7  | Will  | 70000  | 1            |\n\n**Output**\n\n| Department | Employee | Salary |\n|------------|----------|--------|\n| IT         | Max      | 90000  |\n| IT         | Joe      | 85000  |\n| IT         | Randy    | 85000  |\n| IT         | Will     | 70000  |\n| Sales      | Henry    | 80000  |\n| Sales      | Sam      | 60000  |",
    "correctQuery": "WITH RankedSalaries AS (SELECT *, DENSE_RANK() OVER (PARTITION BY departmentId ORDER BY salary DESC) AS salary_rank FROM Employee) SELECT d.name AS Department, rs.name AS Employee, rs.salary AS Salary FROM RankedSalaries rs JOIN Department d ON rs.departmentId = d.id WHERE rs.salary_rank <= 3 ORDER BY Department, Salary DESC, Employee ASC;",
    "sourceTableQuery": "CREATE TABLE Employee (id INT PRIMARY KEY, name VARCHAR(255), salary INT, departmentId INT);\nINSERT INTO Employee (id, name, salary, departmentId) VALUES (1, 'Joe', 85000, 1);\nINSERT INTO Employee (id, name, salary, departmentId) VALUES (2, 'Henry', 80000, 2);\nINSERT INTO Employee (id, name, salary, departmentId) VALUES (3, 'Sam', 60000, 2);\nINSERT INTO Employee (id, name, salary, departmentId) VALUES (4, 'Max', 90000, 1);\nINSERT INTO Employee (id, name, salary, departmentId) VALUES (5, 'Janet', 69000, 1);\nINSERT INTO Employee (id, name, salary, departmentId) VALUES (6, 'Randy', 85000, 1);\nINSERT INTO Employee (id, name, salary, departmentId) VALUES (7, 'Will', 70000, 1);\nCREATE TABLE Department (id INT PRIMARY KEY, name VARCHAR(255));\nINSERT INTO Department (id, name) VALUES (1, 'IT');\nINSERT INTO Department (id, name) VALUES (2, 'Sales');",
    "hints": [
      "Use the `DENSE_RANK()` window function partitioned by department and ordered by salary descending.",
      "Filter the results where the rank is less than or equal to 3."
    ]
  },
  {
    "id": 98,
    "title": "Rising Temperature",
    "difficulty": "Easy",
    "description": "### Problem\nYou are given a `Weather` table. Write a query to find all dates' `id` with higher temperatures compared to its previous dates (yesterday).\nReturn `id`.\n\n### Table: `Weather`\n\n| Column      | Type | Description      |\n|-------------|------|------------------|\n| id          | INT  | Primary key.     |\n| recordDate  | DATE | The date.        |\n| temperature | INT  | Temperature value|\n\n### Example\n\n**Input — Weather**\n\n| id | recordDate | temperature |\n|----|------------|-------------|\n| 1  | 2025-01-01 | 10          |\n| 2  | 2025-01-02 | 25          |\n| 3  | 2025-01-03 | 20          |\n| 4  | 2025-01-04 | 30          |\n\n**Output**\n\n| id |\n|----|\n| 2  |\n| 4  |",
    "correctQuery": "SELECT w1.id FROM Weather w1 JOIN Weather w2 ON julianday(w1.recordDate) - julianday(w2.recordDate) = 1 WHERE w1.temperature > w2.temperature;",
    "sourceTableQuery": "CREATE TABLE Weather (id INT PRIMARY KEY, recordDate DATE, temperature INT);\nINSERT INTO Weather (id, recordDate, temperature) VALUES (1, '2025-01-01', 10);\nINSERT INTO Weather (id, recordDate, temperature) VALUES (2, '2025-01-02', 25);\nINSERT INTO Weather (id, recordDate, temperature) VALUES (3, '2025-01-03', 20);\nINSERT INTO Weather (id, recordDate, temperature) VALUES (4, '2025-01-04', 30);",
    "hints": ["In SQLite, use `julianday()` to perform calculations on dates. You need to join the table to itself where the date difference is 1 day."]
  },
  {
    "id": 99,
    "title": "Trips and Users",
    "difficulty": "Hard",
    "description": "### Problem\nYou are given `Trips` and `Users` tables. The cancellation rate is computed by dividing the number of canceled (by client or driver) requests with unbanned users by the total number of requests with unbanned users on that day.\nWrite a query to find the cancellation rate of requests with unbanned users (both client and driver must not be banned) each day between \"2023-10-01\" and \"2023-10-03\".\nReturn `Day` and `Cancellation Rate` (rounded to 2 decimals).\n\n### Table: `Trips`\n\n| Column     | Type    | Description                |\n|------------|---------|----------------------------|\n| id         | INT     | Primary key.               |\n| client_id  | INT     | Foreign key to Users.      |\n| driver_id  | INT     | Foreign key to Users.      |\n| city_id    | INT     | City ID.                   |\n| status     | VARCHAR | 'completed', 'cancelled_by_driver', etc. |\n| request_at | DATE    | Date of trip.              |\n\n### Table: `Users`\n\n| Column  | Type    | Description        |\n|---------|---------|--------------------|\n| users_id| INT     | Primary key.       |\n| banned  | VARCHAR | 'Yes' or 'No'.     |\n| role    | VARCHAR | 'client', 'driver'.|\n\n### Example Output\n\n| Day        | Cancellation Rate |\n|------------|-------------------|\n| 2023-10-01 | 0.33              |\n| 2023-10-02 | 0.00              |\n| 2023-10-03 | 0.50              |",
    "correctQuery": "WITH UnbannedTrips AS (SELECT t.* FROM Trips t JOIN Users c ON t.client_id = c.users_id AND c.banned = 'No' JOIN Users d ON t.driver_id = d.users_id AND d.banned = 'No'), DailyStats AS (SELECT request_at AS Day, SUM(CASE WHEN status LIKE 'cancelled%' THEN 1 ELSE 0 END) AS cancelled_count, COUNT(id) AS total_count FROM UnbannedTrips WHERE request_at BETWEEN '2023-10-01' AND '2023-10-03' GROUP BY 1) SELECT Day, ROUND(CAST(cancelled_count AS REAL) / total_count, 2) AS \"Cancellation Rate\" FROM DailyStats ORDER BY Day;",
    "sourceTableQuery": "CREATE TABLE Trips (id INT PRIMARY KEY, client_id INT, driver_id INT, city_id INT, status VARCHAR(50), request_at DATE);\nINSERT INTO Trips VALUES (1, 1, 10, 1, 'completed', '2023-10-01');\nINSERT INTO Trips VALUES (2, 2, 11, 1, 'cancelled_by_driver', '2023-10-01');\nINSERT INTO Trips VALUES (3, 3, 12, 6, 'completed', '2023-10-02');\nINSERT INTO Trips VALUES (4, 4, 13, 6, 'cancelled_by_client', '2023-10-03');\nINSERT INTO Trips VALUES (5, 1, 10, 1, 'completed', '2023-10-01');\nINSERT INTO Trips VALUES (6, 1, 10, 1, 'cancelled_by_driver', '2023-10-03');\nCREATE TABLE Users (users_id INT PRIMARY KEY, banned VARCHAR(10), role VARCHAR(10));\nINSERT INTO Users VALUES (1, 'No', 'client');\nINSERT INTO Users VALUES (2, 'Yes', 'client');\nINSERT INTO Users VALUES (3, 'No', 'client');\nINSERT INTO Users VALUES (4, 'No', 'client');\nINSERT INTO Users VALUES (10, 'No', 'driver');\nINSERT INTO Users VALUES (11, 'No', 'driver');\nINSERT INTO Users VALUES (12, 'No', 'driver');\nINSERT INTO Users VALUES (13, 'Yes', 'driver');",
    "hints": [
      "Filter out trips where either the client or the driver is banned.",
      "Group by the request date and use a `CASE` statement inside `SUM()` (or `AVG()`) to count cancelled trips relative to total trips."
    ]
  },
  {
    "id": 100,
    "title": "Exchange Seats",
    "difficulty": "Medium",
    "description": "### Problem\nYou are given a `Seat` table. Write a query to swap the seat id of every two consecutive students. If the number of students is odd, the id of the last student is not swapped.\nReturn the result table ordered by `id` in ascending order.\n\n### Table: `Seat`\n\n| Column | Type    | Description    |\n|--------|---------|----------------|\n| id     | INT     | Primary key.   |\n| student| VARCHAR | Student name.  |\n\n### Example\n\n**Input — Seat**\n\n| id | student |\n|----|---------|\n| 1  | Abbot   |\n| 2  | Doris   |\n| 3  | Emerson |\n| 4  | Green   |\n| 5  | Jeames  |\n\n**Output**\n\n| id | student |\n|----|---------|\n| 1  | Doris   |\n| 2  | Abbot   |\n| 3  | Green   |\n| 4  | Emerson |\n| 5  | Jeames  |",
    "correctQuery": "SELECT CASE WHEN id % 2 = 1 AND id = (SELECT MAX(id) FROM Seat) THEN id WHEN id % 2 = 1 THEN id + 1 ELSE id - 1 END AS id, student FROM Seat ORDER BY id ASC;",
    "sourceTableQuery": "CREATE TABLE Seat (id INT PRIMARY KEY, student VARCHAR(255));\nINSERT INTO Seat (id, student) VALUES (1, 'Abbot');\nINSERT INTO Seat (id, student) VALUES (2, 'Doris');\nINSERT INTO Seat (id, student) VALUES (3, 'Emerson');\nINSERT INTO Seat (id, student) VALUES (4, 'Green');\nINSERT INTO Seat (id, student) VALUES (5, 'Jeames');",
    "hints": ["Use a `CASE` statement to swap IDs: if the id is odd, add 1; if even, subtract 1. Be careful with the last odd-numbered seat."]
  }
]